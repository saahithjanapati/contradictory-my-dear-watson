{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k7ct1AyABbSK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8cSvrykBqGV",
        "outputId": "0f5c7673-8986-41c3-86ac-25b9353ce6d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('csv', data_files = '/content/drive/MyDrive/contradictory-my-dear-watson/data/train.csv')\n",
        "test_dataset = load_dataset('csv', data_files = '/content/drive/MyDrive/contradictory-my-dear-watson/data/test.csv')"
      ],
      "metadata": {
        "id": "-qhIDVOwBt8J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZbXpR6HB10F",
        "outputId": "1cd7341b-12e9-4794-c617-bebb508c3743"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'premise', 'hypothesis', 'lang_abv', 'language', 'label'],\n",
              "        num_rows: 12120\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTxS_Om2B47i",
        "outputId": "254dcf40-d0bf-43a1-dd42-0d5288001b8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '5130fd2cb5', 'premise': 'and these comments were considered in formulating the interim rules.', 'hypothesis': 'The rules developed in the interim were put together with these comments in mind.', 'lang_abv': 'en', 'language': 'English', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fjpyn4eBB5NP",
        "outputId": "b2735fbd-5977-4053-f431-45a5efcc3bba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'premise', 'hypothesis', 'lang_abv', 'language'],\n",
              "        num_rows: 5195\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84P7dqWeB5SN",
        "outputId": "db78b504-b360-45bd-b486-24f5196ecead"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'c6d58c3f69', 'premise': 'بکس، کیسی، راہیل، یسعیاہ، کیلی، کیلی، اور کولمبین ہائی اسکول کے دوسرے طلبا کے نام سے بکسوں کو نشان زد کیا جائے گا جس نے اس سال پہلے اپنی زندگی کھو دی', 'hypothesis': 'کیسی کے لئے کوئی یادگار نہیں ہوگا, کولمین ہائی اسکول کے طالب علموں میں سے ایک جو مر گیا.', 'lang_abv': 'ur', 'language': 'Urdu'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split the training dataset into train/validation\n",
        "split_dataset = train_dataset['train'].train_test_split(\n",
        "    test_size=0.1,\n",
        "    seed=42,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_ds_orig = split_dataset['train']\n",
        "val_ds_orig = split_dataset['test']\n",
        "test_ds_orig = test_dataset['train']"
      ],
      "metadata": {
        "id": "rUh8r_u8B5VE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training dataset length: {len(train_ds_orig)}\")\n",
        "print(f\"Validation dataset length: {len(val_ds_orig)}\")\n",
        "print(f\"Test dataset length: {len(test_ds_orig)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiPBbzCpB5XZ",
        "outputId": "95611fa5-1675-4a6f-c1e1-8d39f7681ea2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset length: 10908\n",
            "Validation dataset length: 1212\n",
            "Test dataset length: 5195\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds_orig[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8MgxZTaI7PF",
        "outputId": "ed250ec9-d0e3-4cec-a67e-83649c3550b2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '32cb965cb9', 'premise': 'There is very little to see here, or at the ruined Essene monastery of Qumran itself.', 'hypothesis': 'Most visitors skip this city, or only stay here a night while passing through.', 'lang_abv': 'en', 'language': 'English', 'label': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "template = \"Consider the following premise: {premise}.\\nDoes the premise entail the following hypothesis: {hypothesis}?\\nPlease answer with: 'yes', 'no', or 'maybe'.\\n{label_text}\"\n",
        "test_template = \"Consider the following premise: {premise}.\\nDoes the premise entail the following hypothesis: {hypothesis}?\\nPlease answer with: 'yes', 'no', or 'maybe'.\\n\"\n",
        "\n",
        "# 0 for entailment, 1 for neutral, 2 for contradiction\n",
        "label_to_text_map = {\n",
        "      0: \"yes\",\n",
        "      1: \"maybe\",\n",
        "      2: \"no\"\n",
        "}\n",
        "\n",
        "class WatsonDataset(Dataset):\n",
        "  def __init__(self, orig_ds, is_train=True):\n",
        "    self.ds = orig_ds\n",
        "    self.is_train = is_train\n",
        "\n",
        "  def __getitem__(self, x):\n",
        "    row = self.ds[x]\n",
        "    premise = row['premise']\n",
        "    hypothesis = row['hypothesis']\n",
        "    label = label_to_text_map[row['label']]\n",
        "    label_idx = row['label']\n",
        "\n",
        "    if self.is_train:\n",
        "      text = template.format(premise = premise, hypothesis = hypothesis, label_text=label)\n",
        "    else:\n",
        "      text = test_template.format(premise = premise, hypothesis = hypothesis)\n",
        "    return text, label_idx\n",
        "\n",
        "  def __len__(self, ):\n",
        "    return len(self.ds)"
      ],
      "metadata": {
        "id": "wvjWNBkgB5cW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model, PeftModel, TaskType"
      ],
      "metadata": {
        "id": "8-D9lGeoWmRu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-1.7B-Base\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-1.7B-Base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdvV6LgKF1H",
        "outputId": "acde6b17-5f35-4b28-e882-3ace784f7a22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.padding_side = 'left'"
      ],
      "metadata": {
        "id": "YLJq22KMMv33"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(base_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s6EjIWnXiv9",
        "outputId": "40a17c0f-4232-49c3-fbf1-636c487cf357"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen3ForCausalLM(\n",
            "  (model): Qwen3Model(\n",
            "    (embed_tokens): Embedding(151936, 2048)\n",
            "    (layers): ModuleList(\n",
            "      (0-27): 28 x Qwen3DecoderLayer(\n",
            "        (self_attn): Qwen3Attention(\n",
            "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
            "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
            "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
            "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
            "        )\n",
            "        (mlp): Qwen3MLP(\n",
            "          (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
            "          (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
            "          (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
            "          (act_fn): SiLUActivation()\n",
            "        )\n",
            "        (input_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
            "        (post_attention_layernorm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): Qwen3RMSNorm((2048,), eps=1e-06)\n",
            "    (rotary_emb): Qwen3RotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names = set(n for n, _ in base_model.named_modules())\n",
        "print(names)\n",
        "\n",
        "target_modules = [\"o_proj\", \"k_proj\", \"q_proj\", \"v_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"]\n",
        "\n",
        "lora_cfg = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules=target_modules\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(base_model, lora_cfg)\n",
        "lora_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnbEzCRnY6Xh",
        "outputId": "df54c2e0-4f14-47e8-c47e-ae118babd185"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'', 'model.layers.22.self_attn.v_proj', 'model.layers.9.self_attn.o_proj', 'model.layers.22.mlp.up_proj', 'model.layers.6.mlp.up_proj', 'model.layers.9.self_attn.q_proj', 'model.layers.12.mlp.gate_proj', 'model.layers.9.self_attn.k_norm', 'model.layers.3.self_attn.q_norm', 'model.layers.18', 'model.layers.20.mlp.down_proj', 'model.layers.27.mlp.down_proj', 'model.layers.2', 'model.layers.6.mlp.down_proj', 'model.layers.17.self_attn', 'model.layers.21.self_attn.k_proj', 'model.layers.25.mlp.down_proj', 'model.layers.0.self_attn.q_norm', 'model.layers.21.post_attention_layernorm', 'model.layers.27.mlp.gate_proj', 'model.layers.24.self_attn', 'model.layers.16.self_attn.k_proj', 'model.layers.8.input_layernorm', 'model.layers.4.self_attn.q_proj', 'model.layers.17.self_attn.v_proj', 'model.layers.24.self_attn.k_proj', 'model.layers.15.self_attn', 'model.layers.26.self_attn.q_proj', 'model.layers.27.self_attn', 'model.layers.19.self_attn.q_proj', 'model.layers.17', 'model.layers.17.self_attn.k_proj', 'model.layers.5.self_attn.q_proj', 'model.layers.0', 'model.layers.4.mlp.down_proj', 'model.layers.23.mlp.up_proj', 'model.layers.14.self_attn.k_proj', 'model.layers.13', 'model.layers.2.mlp.gate_proj', 'model.layers.1.self_attn.q_proj', 'model.layers.12.post_attention_layernorm', 'model.layers.1', 'model.layers.8.post_attention_layernorm', 'model.layers.1.post_attention_layernorm', 'model.layers.25.self_attn.k_proj', 'model.layers.27.self_attn.k_norm', 'model.layers.8.mlp.up_proj', 'model.layers.25.mlp', 'model.layers.8.self_attn.o_proj', 'model.layers.19.self_attn.v_proj', 'model.layers.6.self_attn.k_norm', 'model.layers.2.mlp.up_proj', 'model.layers.20.self_attn.k_proj', 'model.layers.8.self_attn.q_norm', 'model.layers.8', 'model.layers.0.mlp', 'model.layers.14.self_attn', 'model.layers.8.self_attn', 'model.layers.7.mlp.gate_proj', 'model.layers.5.self_attn.v_proj', 'model.layers.10.mlp.down_proj', 'model.layers.21.mlp.up_proj', 'model.layers.24.self_attn.o_proj', 'model.layers.0.self_attn.k_norm', 'model.layers.18.mlp.gate_proj', 'model.layers.7.mlp.down_proj', 'model.layers.10.self_attn.k_norm', 'model.layers.7.self_attn.k_proj', 'model.layers.9.mlp.up_proj', 'model.layers.18.mlp.down_proj', 'model.layers.23.self_attn.k_norm', 'model.layers.5.self_attn.k_norm', 'model.layers.13.input_layernorm', 'model.layers.11.self_attn.q_norm', 'model.layers.16.self_attn.k_norm', 'model.layers.10.post_attention_layernorm', 'model.layers.17.mlp.up_proj', 'model.layers.6.mlp', 'model.layers.2.self_attn.q_proj', 'model.layers.24.mlp', 'model.layers.9.self_attn.v_proj', 'model.layers.7.self_attn.v_proj', 'model.layers.5.self_attn.o_proj', 'model.layers.1.mlp.gate_proj', 'model.layers.2.self_attn.q_norm', 'model.layers.15.mlp.down_proj', 'model.layers.0.post_attention_layernorm', 'model.layers.2.mlp', 'model.layers.17.self_attn.o_proj', 'model.layers.5.post_attention_layernorm', 'model.layers.25', 'model.layers.8.self_attn.v_proj', 'model.layers.14.post_attention_layernorm', 'model.layers.2.post_attention_layernorm', 'model.layers.5.mlp.gate_proj', 'model.layers.12.self_attn.q_norm', 'model.layers.1.mlp.down_proj', 'model.layers.23.self_attn', 'model.layers.23.self_attn.k_proj', 'model.layers.18.mlp', 'model.layers.1.input_layernorm', 'model.layers.22.post_attention_layernorm', 'model.layers.8.self_attn.k_proj', 'model.layers.23.self_attn.o_proj', 'model.layers.3.mlp', 'model.layers.22.input_layernorm', 'model.layers.25.post_attention_layernorm', 'model.layers.10.self_attn.o_proj', 'model.layers.1.self_attn.q_norm', 'model.layers.8.mlp.act_fn', 'model.layers.20', 'model.layers.20.self_attn.o_proj', 'model.layers.2.self_attn.v_proj', 'model.layers.24.self_attn.k_norm', 'model.layers.13.mlp.up_proj', 'model.layers.10.self_attn.q_norm', 'model.layers.9.self_attn.q_norm', 'model.layers.3.mlp.gate_proj', 'model.layers.26.mlp', 'model.layers.10.input_layernorm', 'model.layers.16.self_attn.q_norm', 'model.layers.16.self_attn.q_proj', 'model.layers.22.self_attn.k_proj', 'model.layers.5.mlp', 'model.layers.16.self_attn', 'model.layers.19.self_attn', 'model.layers.21.mlp.down_proj', 'model.layers.21.mlp.gate_proj', 'model.layers.0.input_layernorm', 'model.layers.4.mlp.up_proj', 'model.layers.15.post_attention_layernorm', 'model.layers.5.mlp.act_fn', 'model.layers.7.mlp.up_proj', 'model.layers.23.mlp.act_fn', 'model.layers.4.self_attn.v_proj', 'model.layers.3.mlp.up_proj', 'model.layers.22.self_attn.q_proj', 'model.layers.6.self_attn.v_proj', 'model.norm', 'model.layers.8.mlp.down_proj', 'model.layers.0.mlp.up_proj', 'model.layers.23.self_attn.q_norm', 'model.layers.26.mlp.gate_proj', 'model.layers.6', 'model.layers.27.input_layernorm', 'model.rotary_emb', 'model.layers.22', 'model.layers.18.self_attn.v_proj', 'model.layers.12.self_attn.o_proj', 'model.layers.27.self_attn.q_proj', 'model.layers.7.self_attn.q_proj', 'model.layers.27.self_attn.q_norm', 'model.layers.15.mlp.gate_proj', 'model.layers.11.mlp.gate_proj', 'model.layers.1.self_attn.v_proj', 'model.layers.18.self_attn.q_norm', 'model.layers.11.post_attention_layernorm', 'model.layers.20.self_attn.q_proj', 'model.layers.18.mlp.up_proj', 'model.layers.21.self_attn.q_norm', 'model.layers.17.mlp.act_fn', 'model.layers.19.mlp.act_fn', 'model.layers.15.self_attn.k_norm', 'model.layers.15.self_attn.k_proj', 'model.layers.19.mlp.up_proj', 'model.layers.11.self_attn.o_proj', 'model.layers.19.mlp.gate_proj', 'model.layers.10.self_attn.q_proj', 'model.layers.17.self_attn.k_norm', 'model.layers.1.self_attn.k_proj', 'model.layers.2.self_attn.k_norm', 'model.layers.21.self_attn', 'model.layers.14.mlp', 'model.layers.15.input_layernorm', 'model.layers.24.mlp.gate_proj', 'model.layers.24', 'model.layers.9.self_attn', 'model.layers.14.self_attn.q_norm', 'model.layers.16.mlp.act_fn', 'model.layers.11.self_attn.v_proj', 'model.layers.22.self_attn.q_norm', 'model.layers.5.self_attn.q_norm', 'model.layers.13.self_attn.o_proj', 'model.layers.9.mlp.gate_proj', 'model.layers.12.mlp.down_proj', 'model.layers.2.mlp.down_proj', 'model.layers.17.self_attn.q_proj', 'model.layers.15.mlp', 'model.layers.24.post_attention_layernorm', 'model.layers.11.mlp.up_proj', 'model.layers.21.self_attn.k_norm', 'model.layers.17.input_layernorm', 'model.layers.24.self_attn.q_proj', 'model.layers.17.mlp.gate_proj', 'model.layers.23.post_attention_layernorm', 'model.layers.19.input_layernorm', 'model.layers.20.self_attn.v_proj', 'model.layers.0.mlp.down_proj', 'model.layers.26.mlp.down_proj', 'model.layers.13.self_attn.k_proj', 'model.layers.20.mlp', 'model.layers.4.self_attn.k_norm', 'model.layers.27.mlp', 'model.layers.5', 'model.layers.24.self_attn.q_norm', 'model.layers.24.mlp.down_proj', 'model.layers.6.post_attention_layernorm', 'model.layers.12.self_attn.v_proj', 'model.layers.19.self_attn.o_proj', 'model.layers.23.input_layernorm', 'model.layers.10.mlp.gate_proj', 'model.layers.21.self_attn.v_proj', 'model.layers.21.mlp', 'model.layers.5.mlp.down_proj', 'model.layers.22.mlp', 'model.layers.17.mlp.down_proj', 'model.layers.13.self_attn.k_norm', 'model.layers.4.post_attention_layernorm', 'model.layers.25.self_attn', 'model.layers.21.self_attn.o_proj', 'model.layers.26.self_attn.k_proj', 'model.layers.4.self_attn', 'model.layers.16.post_attention_layernorm', 'model.layers.21.input_layernorm', 'model.layers.7.self_attn', 'model.layers.4.self_attn.o_proj', 'model.layers.6.self_attn', 'model.layers.7.mlp', 'model.layers.18.input_layernorm', 'model.layers.10.self_attn.k_proj', 'model.layers.0.self_attn.k_proj', 'model.layers.23.self_attn.v_proj', 'model.layers.27.post_attention_layernorm', 'model.layers.20.mlp.gate_proj', 'model.layers.3.post_attention_layernorm', 'model.layers.18.self_attn.q_proj', 'model.layers.26.mlp.act_fn', 'model.layers.20.self_attn.q_norm', 'model.layers.11.input_layernorm', 'model.layers.3.input_layernorm', 'model.layers.4', 'model.layers.20.self_attn.k_norm', 'model.layers.24.mlp.up_proj', 'model.layers.20.mlp.act_fn', 'model.layers.0.mlp.gate_proj', 'model.layers.11.mlp.act_fn', 'model.layers.2.self_attn.k_proj', 'model.layers.1.self_attn', 'model.layers.18.post_attention_layernorm', 'model.layers.12', 'model.layers.7.post_attention_layernorm', 'model.layers.23.mlp.gate_proj', 'model.layers.6.input_layernorm', 'model.layers.1.mlp.up_proj', 'model.layers.14.input_layernorm', 'model.layers.5.input_layernorm', 'model.layers.3.self_attn', 'model.layers.12.self_attn', 'model.layers.22.self_attn', 'model.layers.7.self_attn.q_norm', 'model.layers.25.mlp.gate_proj', 'model.layers.27.mlp.act_fn', 'model.layers.7.self_attn.k_norm', 'model.layers.24.mlp.act_fn', 'model.layers.10.mlp.up_proj', 'model.layers.13.self_attn', 'model.layers.26.post_attention_layernorm', 'model.layers.13.post_attention_layernorm', 'model.layers.15.mlp.act_fn', 'model.layers.19.self_attn.q_norm', 'model.layers.12.mlp.act_fn', 'model.layers.27.self_attn.v_proj', 'model.layers.17.self_attn.q_norm', 'model.layers.8.mlp', 'model.layers.27.self_attn.o_proj', 'model.layers.26.self_attn', 'model.layers.21', 'model.layers.19', 'model.layers.6.self_attn.q_norm', 'model.layers.3.self_attn.o_proj', 'model.layers.16.mlp.up_proj', 'model.layers.23', 'model.layers.23.mlp', 'model.layers.10.mlp', 'model.layers.9.input_layernorm', 'model.layers.4.input_layernorm', 'model.layers.13.self_attn.v_proj', 'model.layers.13.mlp.down_proj', 'model.layers.4.self_attn.k_proj', 'model.layers.18.self_attn', 'model.layers.26.mlp.up_proj', 'model.layers.26.input_layernorm', 'model.layers.5.mlp.up_proj', 'model.layers.13.mlp', 'model.layers.1.mlp', 'model.layers.12.self_attn.q_proj', 'model.layers.9', 'model.layers.6.mlp.gate_proj', 'model.layers.13.self_attn.q_proj', 'model.layers.4.mlp.gate_proj', 'model.layers.1.self_attn.o_proj', 'model.layers.7.input_layernorm', 'model.layers.14.self_attn.q_proj', 'model.layers.21.mlp.act_fn', 'model.layers.25.self_attn.q_norm', 'model.layers.8.self_attn.q_proj', 'model.layers.11.self_attn.k_norm', 'model.layers.26', 'model.layers.19.mlp.down_proj', 'model.layers.12.self_attn.k_norm', 'model.layers.12.mlp', 'model.layers.26.self_attn.v_proj', 'model.layers.25.self_attn.v_proj', 'model.layers.3.mlp.down_proj', 'model.layers.22.mlp.down_proj', 'model.layers.7.self_attn.o_proj', 'model.layers.13.mlp.act_fn', 'model.layers.19.self_attn.k_proj', 'model.layers.3.self_attn.v_proj', 'model.layers.0.self_attn.v_proj', 'model.layers.11', 'model.layers.18.self_attn.o_proj', 'model.layers.6.self_attn.k_proj', 'model.layers.0.mlp.act_fn', 'model.layers.15', 'model.layers.16.mlp.gate_proj', 'model.layers.11.self_attn.q_proj', 'model.layers.17.mlp', 'model.layers.1.self_attn.k_norm', 'model.layers.9.self_attn.k_proj', 'model.layers.20.input_layernorm', 'model.layers.13.mlp.gate_proj', 'model.layers.9.mlp', 'model.layers.0.self_attn.q_proj', 'model.layers.22.mlp.gate_proj', 'model.layers.16', 'model.layers.18.self_attn.k_proj', 'model.embed_tokens', 'model.layers.10.mlp.act_fn', 'model.layers.15.self_attn.q_proj', 'model.layers.14.self_attn.k_norm', 'model.layers.5.self_attn', 'model.layers.19.mlp', 'model.layers.3', 'model.layers.25.mlp.act_fn', 'model.layers.6.mlp.act_fn', 'model.layers.16.mlp.down_proj', 'model.layers.3.self_attn.k_norm', 'model.layers.12.self_attn.k_proj', 'model.layers.4.self_attn.q_norm', 'model.layers.15.self_attn.v_proj', 'model.layers.27', 'model', 'model.layers.1.mlp.act_fn', 'model.layers.20.post_attention_layernorm', 'model.layers.17.post_attention_layernorm', 'model.layers.14.mlp.up_proj', 'model.layers.25.self_attn.o_proj', 'model.layers.2.self_attn', 'model.layers.9.mlp.down_proj', 'model.layers.3.self_attn.k_proj', 'model.layers.21.self_attn.q_proj', 'model.layers.4.mlp.act_fn', 'model.layers.11.mlp', 'model.layers.22.self_attn.k_norm', 'model.layers.14', 'model.layers.14.mlp.down_proj', 'model.layers.4.mlp', 'model.layers.3.self_attn.q_proj', 'model.layers.10.self_attn', 'model.layers.9.mlp.act_fn', 'model.layers.12.mlp.up_proj', 'model.layers.16.mlp', 'model.layers.2.self_attn.o_proj', 'model.layers.10', 'model.layers.23.self_attn.q_proj', 'model.layers.25.input_layernorm', 'model.layers.27.self_attn.k_proj', 'model.layers.25.self_attn.q_proj', 'model.layers.6.self_attn.q_proj', 'model.layers.15.mlp.up_proj', 'model.layers.19.post_attention_layernorm', 'model.layers.6.self_attn.o_proj', 'model.layers.0.self_attn.o_proj', 'lm_head', 'model.layers.2.mlp.act_fn', 'model.layers.7', 'model.layers.15.self_attn.o_proj', 'model.layers.0.self_attn', 'model.layers.12.input_layernorm', 'model.layers.7.mlp.act_fn', 'model.layers.10.self_attn.v_proj', 'model.layers.11.mlp.down_proj', 'model.layers.3.mlp.act_fn', 'model.layers.26.self_attn.k_norm', 'model.layers.24.self_attn.v_proj', 'model.layers.20.self_attn', 'model.layers.9.post_attention_layernorm', 'model.layers.26.self_attn.q_norm', 'model.layers.11.self_attn.k_proj', 'model.layers.16.self_attn.v_proj', 'model.layers.15.self_attn.q_norm', 'model.layers.8.self_attn.k_norm', 'model.layers.25.self_attn.k_norm', 'model.layers.16.input_layernorm', 'model.layers.14.mlp.gate_proj', 'model.layers.14.self_attn.o_proj', 'model.layers.26.self_attn.o_proj', 'model.layers.13.self_attn.q_norm', 'model.layers.22.mlp.act_fn', 'model.layers.24.input_layernorm', 'model.layers.5.self_attn.k_proj', 'model.layers.8.mlp.gate_proj', 'model.layers.14.mlp.act_fn', 'model.layers.27.mlp.up_proj', 'model.layers', 'model.layers.19.self_attn.k_norm', 'model.layers.11.self_attn', 'model.layers.16.self_attn.o_proj', 'model.layers.14.self_attn.v_proj', 'model.layers.25.mlp.up_proj', 'model.layers.18.self_attn.k_norm', 'model.layers.18.mlp.act_fn', 'model.layers.20.mlp.up_proj', 'model.layers.2.input_layernorm', 'model.layers.22.self_attn.o_proj', 'model.layers.23.mlp.down_proj'}\n",
            "trainable params: 17,432,576 || all params: 1,738,007,552 || trainable%: 1.0030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbLKu2HVOTJ5",
        "outputId": "74df7bab-bec1-4265-c64d-1ad6f132bb89"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Qwen2TokenizerFast(name_or_path='Qwen/Qwen3-1.7B-Base', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|endoftext|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151665: AddedToken(\"<tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151666: AddedToken(\"</tool_response>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151667: AddedToken(\"<think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "\t151668: AddedToken(\"</think>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "def collate_fn(batch, is_train=True):\n",
        "  texts = [row[0] for row in batch]\n",
        "  labels = [row[1] for row in batch]\n",
        "\n",
        "  inputs = tokenizer(texts, return_tensors = 'pt', padding=True)\n",
        "  actual_labels = inputs[\"input_ids\"] # (B,T)\n",
        "\n",
        "  # set everything to -100 except the last token, which is the answer (either yes, no, or maybe)\n",
        "  text_labels = inputs[\"input_ids\"].clone()\n",
        "  text_labels[:, 0:-1] = -100\n",
        "\n",
        "  labels = torch.tensor(labels)\n",
        "  return inputs, text_labels, labels\n",
        "\n"
      ],
      "metadata": {
        "id": "cynH-xZlB5es"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_ds = WatsonDataset(train_ds_orig, is_train=True)\n",
        "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn = partial(collate_fn, is_train=True))\n",
        "\n",
        "\n",
        "for inputs, text_label, label in train_loader:\n",
        "  print(inputs, text_label, label)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX5ZinN2B5hC",
        "outputId": "0bbeaf51-b911-43b3-ab29-d7e78a833bc9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[151643, 151643, 151643,  ...,  36760,  23569,   9693],\n",
            "        [151643, 151643, 151643,  ...,  36760,  23569,   2152],\n",
            "        [151643, 151643, 151643,  ...,  36760,  23569,  36760],\n",
            "        ...,\n",
            "        [151643, 151643, 151643,  ...,  36760,  23569,   2152],\n",
            "        [151643, 151643, 151643,  ...,  36760,  23569,   2152],\n",
            "        [151643, 151643, 151643,  ...,  36760,  23569,  36760]]), 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1]])} tensor([[ -100,  -100,  -100,  ...,  -100,  -100,  9693],\n",
            "        [ -100,  -100,  -100,  ...,  -100,  -100,  2152],\n",
            "        [ -100,  -100,  -100,  ...,  -100,  -100, 36760],\n",
            "        ...,\n",
            "        [ -100,  -100,  -100,  ...,  -100,  -100,  2152],\n",
            "        [ -100,  -100,  -100,  ...,  -100,  -100,  2152],\n",
            "        [ -100,  -100,  -100,  ...,  -100,  -100, 36760]]) tensor([0, 2, 1, 1, 1, 2, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_tensor = tokenizer.decode(inputs[\"input_ids\"][1].tolist())\n",
        "print(first_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoddwOceB5jp",
        "outputId": "e8116525-8a7e-4716-f995-afe07078aef6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Consider the following premise: they really do i i sometimes think that that should be limited more.\n",
            "Does the premise entail the following hypothesis: No, I do not think they need any additional limits.?\n",
            "Please answer with: 'yes', 'no', or 'maybe'.\n",
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "Op4z_vC4PVJ9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "# training loop time\n",
        "num_epochs = 2\n",
        "lr = 1e-5\n",
        "max_grad_norm = 1.0\n",
        "lora_model.to(device)\n",
        "optimizer = optim.AdamW(lora_model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "YtiwSMlrB5l-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIra1O9rURgg",
        "outputId": "92e72077-01f1-4ebd-82c1-5ebd9557d2ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"qwen-watson-sft\", config={\n",
        "    \"epochs\": num_epochs,\n",
        "    \"learning_rate\": lr,\n",
        "    \"max_grad_norm\": max_grad_norm,\n",
        "})\n",
        "\n",
        "\n",
        "iter_idx = 0\n",
        "print_every = 20\n",
        "for epoch_idx in range(num_epochs):\n",
        "  lora_model.train()\n",
        "\n",
        "  for inputs, text_labels, labels in train_loader:\n",
        "\n",
        "    inputs = {k: v.to(device) for k,v in inputs.items()}\n",
        "    text_labels = text_labels.to(device)\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "\n",
        "    out = lora_model(**inputs, labels = text_labels)\n",
        "    loss = out.loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    clip_grad_norm_(lora_model.parameters(), max_grad_norm)\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    # calculate accuracy\n",
        "    logits = out.logits # (B, T, V)\n",
        "    relevant_logits = logits[:, -2, [9693, 36760, 2152]]\n",
        "    _, preds = torch.max(relevant_logits, dim=1)\n",
        "\n",
        "    num_correct = torch.sum((preds.cpu() == labels).to(torch.int)).item()\n",
        "    num_samples = len(input_ids)\n",
        "    acc = num_correct / num_samples\n",
        "\n",
        "    if iter_idx % print_every == 0:\n",
        "      print(f\"Epoch {epoch_idx} - Iter {iter_idx}: Loss - {loss.item()}, Accuracy - {acc}\")\n",
        "\n",
        "    wandb.log({\"train/loss\": loss.item(), \"train/acc\": acc, \"epoch\": epoch_idx, \"iter\": iter_idx})\n",
        "    iter_idx += 1\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hs2zSnoXQjo2",
        "outputId": "7ed72123-be55-419f-a7e5-9a0684e6b96d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msaahith\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251107_223438-u3010mik</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saahith/qwen-watson-sft/runs/u3010mik' target=\"_blank\">fresh-cloud-5</a></strong> to <a href='https://wandb.ai/saahith/qwen-watson-sft' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saahith/qwen-watson-sft' target=\"_blank\">https://wandb.ai/saahith/qwen-watson-sft</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saahith/qwen-watson-sft/runs/u3010mik' target=\"_blank\">https://wandb.ai/saahith/qwen-watson-sft/runs/u3010mik</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 - Iter 0: Loss - 1.3406808376312256, Accuracy - 0.5\n",
            "Epoch 0 - Iter 20: Loss - 0.6652697324752808, Accuracy - 0.75\n",
            "Epoch 0 - Iter 40: Loss - 0.18012338876724243, Accuracy - 0.875\n",
            "Epoch 0 - Iter 60: Loss - 0.653796911239624, Accuracy - 0.75\n",
            "Epoch 0 - Iter 80: Loss - 1.2924132347106934, Accuracy - 0.5\n",
            "Epoch 0 - Iter 100: Loss - 1.0965030193328857, Accuracy - 0.625\n",
            "Epoch 0 - Iter 120: Loss - 0.690719485282898, Accuracy - 0.625\n",
            "Epoch 0 - Iter 140: Loss - 0.16682054102420807, Accuracy - 1.0\n",
            "Epoch 0 - Iter 160: Loss - 0.2565747797489166, Accuracy - 0.875\n",
            "Epoch 0 - Iter 180: Loss - 0.12195585668087006, Accuracy - 1.0\n",
            "Epoch 0 - Iter 200: Loss - 1.0670104026794434, Accuracy - 0.625\n",
            "Epoch 0 - Iter 220: Loss - 0.40123820304870605, Accuracy - 0.875\n",
            "Epoch 0 - Iter 240: Loss - 0.2609871029853821, Accuracy - 0.875\n",
            "Epoch 0 - Iter 260: Loss - 0.4555235505104065, Accuracy - 0.875\n",
            "Epoch 0 - Iter 280: Loss - 0.5924045443534851, Accuracy - 0.75\n",
            "Epoch 0 - Iter 300: Loss - 1.2444473505020142, Accuracy - 0.5\n",
            "Epoch 0 - Iter 320: Loss - 0.5688513517379761, Accuracy - 0.875\n",
            "Epoch 0 - Iter 340: Loss - 0.203893780708313, Accuracy - 1.0\n",
            "Epoch 0 - Iter 360: Loss - 0.7499538064002991, Accuracy - 0.625\n",
            "Epoch 0 - Iter 380: Loss - 0.564272403717041, Accuracy - 0.75\n",
            "Epoch 0 - Iter 400: Loss - 0.24206209182739258, Accuracy - 1.0\n",
            "Epoch 0 - Iter 420: Loss - 0.7142778635025024, Accuracy - 0.625\n",
            "Epoch 0 - Iter 440: Loss - 0.5810930132865906, Accuracy - 0.875\n",
            "Epoch 0 - Iter 460: Loss - 0.3731354773044586, Accuracy - 0.75\n",
            "Epoch 0 - Iter 480: Loss - 0.9352560639381409, Accuracy - 0.875\n",
            "Epoch 0 - Iter 500: Loss - 0.2600690424442291, Accuracy - 0.875\n",
            "Epoch 0 - Iter 520: Loss - 0.60288006067276, Accuracy - 0.875\n",
            "Epoch 0 - Iter 540: Loss - 1.238788366317749, Accuracy - 0.5\n",
            "Epoch 0 - Iter 560: Loss - 0.41177132725715637, Accuracy - 0.875\n",
            "Epoch 0 - Iter 580: Loss - 0.4665432274341583, Accuracy - 0.875\n",
            "Epoch 0 - Iter 600: Loss - 0.3989420533180237, Accuracy - 0.75\n",
            "Epoch 0 - Iter 620: Loss - 1.4990832805633545, Accuracy - 0.5\n",
            "Epoch 0 - Iter 640: Loss - 0.19909048080444336, Accuracy - 0.875\n",
            "Epoch 0 - Iter 660: Loss - 0.4056400656700134, Accuracy - 0.75\n",
            "Epoch 0 - Iter 680: Loss - 0.31144875288009644, Accuracy - 0.875\n",
            "Epoch 0 - Iter 700: Loss - 0.3530210554599762, Accuracy - 0.875\n",
            "Epoch 0 - Iter 720: Loss - 0.1731603890657425, Accuracy - 1.0\n",
            "Epoch 0 - Iter 740: Loss - 0.3327235281467438, Accuracy - 0.875\n",
            "Epoch 0 - Iter 760: Loss - 0.48468369245529175, Accuracy - 0.75\n",
            "Epoch 0 - Iter 780: Loss - 0.8196964263916016, Accuracy - 0.875\n",
            "Epoch 0 - Iter 800: Loss - 0.07466341555118561, Accuracy - 1.0\n",
            "Epoch 0 - Iter 820: Loss - 0.3629375100135803, Accuracy - 0.75\n",
            "Epoch 0 - Iter 840: Loss - 0.43518194556236267, Accuracy - 0.75\n",
            "Epoch 0 - Iter 860: Loss - 0.23767271637916565, Accuracy - 0.875\n",
            "Epoch 0 - Iter 880: Loss - 0.2834467887878418, Accuracy - 0.875\n",
            "Epoch 0 - Iter 900: Loss - 0.6783912181854248, Accuracy - 0.625\n",
            "Epoch 0 - Iter 920: Loss - 0.2695215940475464, Accuracy - 0.875\n",
            "Epoch 0 - Iter 940: Loss - 0.5015313029289246, Accuracy - 0.75\n",
            "Epoch 0 - Iter 960: Loss - 0.25073501467704773, Accuracy - 0.875\n",
            "Epoch 0 - Iter 980: Loss - 0.34446388483047485, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1000: Loss - 0.6266595721244812, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1020: Loss - 0.4105132520198822, Accuracy - 0.875\n",
            "Epoch 0 - Iter 1040: Loss - 0.18626061081886292, Accuracy - 1.0\n",
            "Epoch 0 - Iter 1060: Loss - 0.5167980194091797, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1080: Loss - 0.6434400081634521, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1100: Loss - 0.7066559791564941, Accuracy - 0.625\n",
            "Epoch 0 - Iter 1120: Loss - 0.3120686411857605, Accuracy - 1.0\n",
            "Epoch 0 - Iter 1140: Loss - 0.30123040080070496, Accuracy - 0.875\n",
            "Epoch 0 - Iter 1160: Loss - 0.015191810205578804, Accuracy - 1.0\n",
            "Epoch 0 - Iter 1180: Loss - 0.2832634449005127, Accuracy - 0.875\n",
            "Epoch 0 - Iter 1200: Loss - 0.838524580001831, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1220: Loss - 0.10658438503742218, Accuracy - 1.0\n",
            "Epoch 0 - Iter 1240: Loss - 1.2671234607696533, Accuracy - 0.625\n",
            "Epoch 0 - Iter 1260: Loss - 0.3503141403198242, Accuracy - 0.875\n",
            "Epoch 0 - Iter 1280: Loss - 0.05450635403394699, Accuracy - 1.0\n",
            "Epoch 0 - Iter 1300: Loss - 1.0344812870025635, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1320: Loss - 0.05392789840698242, Accuracy - 1.0\n",
            "Epoch 0 - Iter 1340: Loss - 0.8324440717697144, Accuracy - 0.75\n",
            "Epoch 0 - Iter 1360: Loss - 0.2750060558319092, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1380: Loss - 0.5919307470321655, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1400: Loss - 0.883659303188324, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1420: Loss - 0.5632444620132446, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1440: Loss - 0.5131292939186096, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1460: Loss - 0.23225900530815125, Accuracy - 1.0\n",
            "Epoch 1 - Iter 1480: Loss - 0.5975905656814575, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1500: Loss - 0.34824204444885254, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1520: Loss - 0.29633796215057373, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1540: Loss - 0.3253769278526306, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1560: Loss - 0.15388743579387665, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1580: Loss - 1.4407707452774048, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1600: Loss - 0.8286763429641724, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1620: Loss - 0.5539327263832092, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1640: Loss - 0.6057860255241394, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1660: Loss - 0.6273601651191711, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1680: Loss - 0.5263392925262451, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1700: Loss - 0.6534058451652527, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1720: Loss - 0.5057618021965027, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1740: Loss - 0.17274153232574463, Accuracy - 1.0\n",
            "Epoch 1 - Iter 1760: Loss - 0.5419564843177795, Accuracy - 0.75\n",
            "Epoch 1 - Iter 1780: Loss - 0.0974976196885109, Accuracy - 1.0\n",
            "Epoch 1 - Iter 1800: Loss - 0.41761335730552673, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1820: Loss - 0.9759608507156372, Accuracy - 0.625\n",
            "Epoch 1 - Iter 1840: Loss - 0.4432436227798462, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1860: Loss - 0.1832309514284134, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1880: Loss - 0.39618977904319763, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1900: Loss - 0.10599736869335175, Accuracy - 1.0\n",
            "Epoch 1 - Iter 1920: Loss - 0.08616382628679276, Accuracy - 1.0\n",
            "Epoch 1 - Iter 1940: Loss - 0.1734306514263153, Accuracy - 1.0\n",
            "Epoch 1 - Iter 1960: Loss - 0.20533747971057892, Accuracy - 0.875\n",
            "Epoch 1 - Iter 1980: Loss - 0.6032404899597168, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2000: Loss - 0.6285420656204224, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2020: Loss - 0.5365608930587769, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2040: Loss - 0.03752269968390465, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2060: Loss - 1.062875747680664, Accuracy - 0.625\n",
            "Epoch 1 - Iter 2080: Loss - 0.8676466941833496, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2100: Loss - 0.7422482371330261, Accuracy - 0.625\n",
            "Epoch 1 - Iter 2120: Loss - 0.439753919839859, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2140: Loss - 0.14066588878631592, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2160: Loss - 0.7058128118515015, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2180: Loss - 0.5760974287986755, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2200: Loss - 0.4709315299987793, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2220: Loss - 0.5885094404220581, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2240: Loss - 0.694154679775238, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2260: Loss - 0.5983210802078247, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2280: Loss - 0.6907662749290466, Accuracy - 0.625\n",
            "Epoch 1 - Iter 2300: Loss - 0.3489468991756439, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2320: Loss - 0.5806457996368408, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2340: Loss - 0.24023942649364471, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2360: Loss - 0.3416343629360199, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2380: Loss - 0.5398674607276917, Accuracy - 0.75\n",
            "Epoch 1 - Iter 2400: Loss - 0.2996039092540741, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2420: Loss - 0.5323434472084045, Accuracy - 0.625\n",
            "Epoch 1 - Iter 2440: Loss - 0.3097229301929474, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2460: Loss - 0.12714546918869019, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2480: Loss - 0.1951499581336975, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2500: Loss - 0.34833449125289917, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2520: Loss - 0.26686781644821167, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2540: Loss - 0.15385018289089203, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2560: Loss - 0.07680174708366394, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2580: Loss - 0.20508408546447754, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2600: Loss - 0.09038551151752472, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2620: Loss - 0.3124558627605438, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2640: Loss - 0.11730846762657166, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2660: Loss - 0.6702367067337036, Accuracy - 0.625\n",
            "Epoch 1 - Iter 2680: Loss - 0.22196084260940552, Accuracy - 0.875\n",
            "Epoch 1 - Iter 2700: Loss - 0.10948190838098526, Accuracy - 1.0\n",
            "Epoch 1 - Iter 2720: Loss - 0.5778314471244812, Accuracy - 0.75\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>iter</td><td>▁▁▁▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/acc</td><td>█▃▅▆▆▆▅▅▆▃▅█▁▃▅█▅▅█▆▆▆▆█▃█▆▅█▆▆█▆▆▆█▅▅▅▆</td></tr><tr><td>train/loss</td><td>▄▃▃▃▅▃▁▃▃▄▂▂▂▂▂▁▂█▄▄▂▃▂▁▁▂▂▁▅▁▁▂▁▃▃▄▁▁▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>iter</td><td>2727</td></tr><tr><td>train/acc</td><td>1</td></tr><tr><td>train/loss</td><td>0.23264</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fresh-cloud-5</strong> at: <a href='https://wandb.ai/saahith/qwen-watson-sft/runs/u3010mik' target=\"_blank\">https://wandb.ai/saahith/qwen-watson-sft/runs/u3010mik</a><br> View project at: <a href='https://wandb.ai/saahith/qwen-watson-sft' target=\"_blank\">https://wandb.ai/saahith/qwen-watson-sft</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251107_223438-u3010mik/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run inference on validation set"
      ],
      "metadata": {
        "id": "bHWzJLDgB5ol"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_ds = WatsonDataset(train_ds_orig, is_train=True)\n",
        "# train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, collate_fn = partial(collate_fn, is_train=True))\n",
        "\n",
        "\n",
        "val_ds = WatsonDataset(val_ds_orig, is_train = False)\n",
        "val_loader = DataLoader(val_ds, batch_size = 16, shuffle=False, collate_fn = collate_fn)\n",
        "\n",
        "\n",
        "num_correct = 0\n",
        "num_samples = 0\n",
        "\n",
        "lora_model.eval()\n",
        "\n",
        "for inputs, _, labels in tqdm(val_loader):\n",
        "  with torch.no_grad():\n",
        "    inputs = {k: v.to(device) for k,v in inputs.items()}\n",
        "    out = lora_model(**inputs)\n",
        "\n",
        "    # calculate accuracy\n",
        "    logits = out.logits # (B, T, V)\n",
        "    relevant_logits = logits[:, -1, [9693, 36760, 2152]]\n",
        "    _, preds = torch.max(relevant_logits, dim=1)\n",
        "\n",
        "    correct = torch.sum((preds.cpu() == labels).to(torch.int))\n",
        "    num_correct += correct.item()\n",
        "    num_samples += len(preds)\n",
        "\n",
        "\n",
        "accuracy = num_correct / num_samples\n",
        "print(f\"{num_correct}/{num_samples} - {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctqu-vF_Qi2W",
        "outputId": "c4db3fa8-60f5-44a4-a689-747b0f6fe0db"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 76/76 [00:47<00:00,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1030/1212 - 0.8498349834983498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fqi1pv-rjh4s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}