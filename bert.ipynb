{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xtvSmSjwvULV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "\n",
        "print(model)\n",
        "print(\"---------------\")\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t1MVf-gvmjD",
        "outputId": "e8b03da6-6496-4661-c776-ee0b83f8705a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n",
            "---------------\n",
            "BertTokenizer(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlADoi9LvsbO",
        "outputId": "61cf1b88-16d3-4f0d-e058-d413b72bcb19"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('csv', data_files='/content/drive/MyDrive/contradictory-my-dear-watson/data/train.csv')\n",
        "test_dataset = load_dataset('csv',  data_files='/content/drive/MyDrive/contradictory-my-dear-watson/data/test.csv')"
      ],
      "metadata": {
        "id": "6tlKv6D6v1ni"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ag9l7fZxq2V",
        "outputId": "1c35dde2-8e5b-4fae-fb1d-c99370cff960"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'premise', 'hypothesis', 'lang_abv', 'language', 'label'],\n",
              "        num_rows: 12120\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efhGTsTGxy02",
        "outputId": "40e1f1ec-ec68-4ae8-e7c2-168e945043e8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '5130fd2cb5', 'premise': 'and these comments were considered in formulating the interim rules.', 'hypothesis': 'The rules developed in the interim were put together with these comments in mind.', 'lang_abv': 'en', 'language': 'English', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDphDqx3xr0Y",
        "outputId": "1f5623cf-a734-4eed-f73a-5a8403f45844"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'premise', 'hypothesis', 'lang_abv', 'language'],\n",
              "        num_rows: 5195\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset['train'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQQiZn1JwcEI",
        "outputId": "cb94ded7-f95f-4924-e2b9-50e75a6a52ff"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cefcc82292', 'premise': 'هذا هو ما تم نصحنا به.', 'hypothesis': 'عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت الإدارة في السماح لنا بالدخول إلى الأسرار التجارية.', 'lang_abv': 'ar', 'language': 'Arabic'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "FFvFJemOw_VQ",
        "outputId": "9062e64d-4d8f-4a3e-f14e-54b21cf9cce1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 691);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"[CLS] hi ther\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeyUNSP5UCin",
        "outputId": "80f81ca5-e96c-4068-fa87-47e2941077eb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 101, 11520, 10105, 10129, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lU0eALVVuRX",
        "outputId": "6a8bcbf4-8ddf-49f4-f5fe-e7ae3b4ee797"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SPECIAL_TOKENS_ATTRIBUTES',\n",
              " '__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_add_tokens',\n",
              " '_added_tokens_decoder',\n",
              " '_added_tokens_encoder',\n",
              " '_auto_class',\n",
              " '_batch_encode_plus',\n",
              " '_batch_prepare_for_model',\n",
              " '_call_one',\n",
              " '_convert_id_to_token',\n",
              " '_convert_token_to_id',\n",
              " '_convert_token_to_id_with_added_voc',\n",
              " '_create_repo',\n",
              " '_decode',\n",
              " '_decode_use_source_tokenizer',\n",
              " '_encode_plus',\n",
              " '_eventual_warn_about_too_long_sequence',\n",
              " '_eventually_correct_t5_max_length',\n",
              " '_from_pretrained',\n",
              " '_get_files_timestamps',\n",
              " '_get_padding_truncation_strategies',\n",
              " '_in_target_context_manager',\n",
              " '_pad',\n",
              " '_pad_token_type_id',\n",
              " '_processor_class',\n",
              " '_save_pretrained',\n",
              " '_set_model_specific_special_tokens',\n",
              " '_set_processor_class',\n",
              " '_special_tokens_map',\n",
              " '_switch_to_input_mode',\n",
              " '_switch_to_target_mode',\n",
              " '_tokenize',\n",
              " '_update_total_vocab_size',\n",
              " '_update_trie',\n",
              " '_upload_modified_files',\n",
              " 'add_special_tokens',\n",
              " 'add_tokens',\n",
              " 'added_tokens_decoder',\n",
              " 'added_tokens_encoder',\n",
              " 'all_special_ids',\n",
              " 'all_special_tokens',\n",
              " 'all_special_tokens_extended',\n",
              " 'apply_chat_template',\n",
              " 'as_target_tokenizer',\n",
              " 'basic_tokenizer',\n",
              " 'batch_decode',\n",
              " 'batch_encode_plus',\n",
              " 'build_inputs_with_special_tokens',\n",
              " 'chat_template',\n",
              " 'clean_up_tokenization',\n",
              " 'clean_up_tokenization_spaces',\n",
              " 'convert_added_tokens',\n",
              " 'convert_ids_to_tokens',\n",
              " 'convert_tokens_to_ids',\n",
              " 'convert_tokens_to_string',\n",
              " 'create_token_type_ids_from_sequences',\n",
              " 'decode',\n",
              " 'deprecation_warnings',\n",
              " 'do_basic_tokenize',\n",
              " 'do_lower_case',\n",
              " 'encode',\n",
              " 'encode_message_with_chat_template',\n",
              " 'encode_plus',\n",
              " 'extra_special_tokens',\n",
              " 'from_pretrained',\n",
              " 'get_added_vocab',\n",
              " 'get_chat_template',\n",
              " 'get_special_tokens_mask',\n",
              " 'get_vocab',\n",
              " 'ids_to_tokens',\n",
              " 'init_inputs',\n",
              " 'init_kwargs',\n",
              " 'is_fast',\n",
              " 'max_len_sentences_pair',\n",
              " 'max_len_single_sentence',\n",
              " 'model_input_names',\n",
              " 'model_max_length',\n",
              " 'name_or_path',\n",
              " 'num_special_tokens_to_add',\n",
              " 'pad',\n",
              " 'pad_token_type_id',\n",
              " 'padding_side',\n",
              " 'prepare_for_model',\n",
              " 'prepare_for_tokenization',\n",
              " 'prepare_seq2seq_batch',\n",
              " 'pretrained_vocab_files_map',\n",
              " 'push_to_hub',\n",
              " 'register_for_auto_class',\n",
              " 'sanitize_special_tokens',\n",
              " 'save_chat_templates',\n",
              " 'save_pretrained',\n",
              " 'save_vocabulary',\n",
              " 'slow_tokenizer_class',\n",
              " 'special_tokens_map',\n",
              " 'special_tokens_map_extended',\n",
              " 'split_special_tokens',\n",
              " 'tokenize',\n",
              " 'tokens_trie',\n",
              " 'total_vocab_size',\n",
              " 'truncate_sequences',\n",
              " 'truncation_side',\n",
              " 'verbose',\n",
              " 'vocab',\n",
              " 'vocab_files_names',\n",
              " 'vocab_size',\n",
              " 'wordpiece_tokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(101)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mcjKi325UIRT",
        "outputId": "afbd2e92-4ad8-4df8-9e72-daef7cd9aa72"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([101, 101, 11463, 10103, 10131, 102])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6Ufg-x_aULbu",
        "outputId": "7731784a-3573-49d6-f2fd-8f1cc1107555"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] [CLS] 1925 𩾌 et [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"hello\", \"goodbye\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4LL-HkJyjri",
        "outputId": "2b479cc9-2447-4291-ae7f-516ce6e849c8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 61694, 10133,   102, 15198, 87421,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import unicodedata, re\n",
        "\n",
        "CONTROL_CHARS = (\n",
        "    r\"[\\u200B-\\u200F\\u202A-\\u202E\\u2066-\\u2069\\uFEFF]\"  # ZW*, bidi, BOM\n",
        ")\n",
        "def clean_text(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = re.sub(CONTROL_CHARS, \"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "\n",
        "class WatsonDataset(Dataset):\n",
        "  def __init__(self, ds, is_train=True):\n",
        "    self.ds = ds\n",
        "    self.is_train = is_train\n",
        "\n",
        "  def __getitem__(self, x):\n",
        "    row = self.ds[x]\n",
        "    premise = row['premise']\n",
        "    hypothesis = row['hypothesis']\n",
        "    if self.is_train:\n",
        "      label = torch.tensor(row['label'])\n",
        "    my_id = row[\"id\"]\n",
        "\n",
        "    enc = tokenizer(\n",
        "    clean_text(premise),\n",
        "    clean_text(hypothesis),\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True)  # add max_length if you want\n",
        "\n",
        "    return_map = {\n",
        "        \"input_ids\": enc[\"input_ids\"][0],\n",
        "        \"attention_mask\": enc[\"attention_mask\"][0],\n",
        "        \"id\": my_id,\n",
        "        \"token_type_ids\": enc[\"token_type_ids\"][0]\n",
        "    }\n",
        "\n",
        "    if self.is_train:\n",
        "      return_map[\"label\"] = label\n",
        "\n",
        "    return return_map\n",
        "\n",
        "\n",
        "  def __len__(self, ):\n",
        "    return len(self.ds)\n"
      ],
      "metadata": {
        "id": "3dzvJpLcSsjt"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = WatsonDataset(train_dataset[\"train\"], is_train=True)\n",
        "test_ds = WatsonDataset(test_dataset[\"train\"], is_train=False)"
      ],
      "metadata": {
        "id": "qTIcoAKQTCX5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_ds:\n",
        "  print(tokenizer.decode(x['input_ids']))\n",
        "  print(x['attention_mask'])\n",
        "  print(x['label'])\n",
        "  print(x['token_type_ids'])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jtwYM74Vb91",
        "outputId": "572a04b6-20f7-4807-e41a-0ae6fe613790"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] and these comments were considered in formulating the interim rules. [SEP] The rules developed in the interim were put together with these comments in mind. [SEP]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1])\n",
            "tensor(0)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "    input_ids = [row['input_ids'] for row in batch]\n",
        "    attention_masks = [row['attention_mask'] for row in batch]\n",
        "    ids = [row['id'] for row in batch]\n",
        "    token_type_ids = [row['token_type_ids'] for row in batch]\n",
        "\n",
        "    if 'label' in batch[0]:\n",
        "      labels = [row['label'] for row in batch]\n",
        "      labels = torch.stack(labels, dim=0)\n",
        "\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value = 0)\n",
        "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value = 0)\n",
        "    token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
        "\n",
        "    return_map = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks,\n",
        "        \"ids\": ids,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    if 'label' in batch[0]:\n",
        "      return_map['labels'] = labels\n",
        "\n",
        "    return return_map"
      ],
      "metadata": {
        "id": "VSewz0AOTOQm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, collate_fn = my_collate_fn, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, collate_fn = my_collate_fn, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "QoUBNbiYcGN4"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_loader:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J74LzrKc3sk",
        "outputId": "c9b25fa4-3139-44e6-88dd-7b897e680ef5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 10167, 10105,  ...,     0,     0,     0],\n",
            "        [  101, 14518,   117,  ...,     0,     0,     0],\n",
            "        [  101, 11469, 10105,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,   764, 63764,  ...,     0,     0,     0],\n",
            "        [  101,   516, 10409,  ..., 14149,   119,   102],\n",
            "        [  101, 44271, 60880,  ...,     0,     0,     0]]), 'attention_masks': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'ids': ['b743e0b7d0', 'a417c669b8', '2e8ba80197', '1340baca73', '045e43efa4', '3b5f6bf1af', '467158753b', '9275255ab8', '0c1d674391', 'ec65531380', '05d6ec2fe7', 'b40f5e8c63', '12974e2544', 'e82b4b6afa', '470d1ea4f2', '5221d82cef'], 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'labels': tensor([2, 2, 0, 0, 0, 1, 1, 1, 1, 2, 2, 0, 0, 1, 1, 0])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in test_loader:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezBqOo40jL76",
        "outputId": "36b43ded-f9a8-4aa8-c595-74230c67b4cf"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   101,    764,  28744,  ...,  17571,    119,    102],\n",
            "        [   101,  13498,  11917,  ...,      0,      0,      0],\n",
            "        [   101,  10131,  24552,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  26467,    146,  ...,      0,      0,      0],\n",
            "        [   101,    530, 110702,  ...,      0,      0,      0],\n",
            "        [   101,  40690,    117,  ...,      0,      0,      0]]), 'attention_masks': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'ids': ['c6d58c3f69', 'cefcc82292', 'e98005252c', '58518c10ba', 'c32b0d16df', 'aa2510d454', '865d1c7b16', 'a16f7ed56b', '6d9fa191e6', 'c156e8fed5', 'f11f1ffffe', 'd41b559e9f', '40a9b0f08e', 'd8f3da717a', '126e3cfa1b', '4e9266e800'], 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "gV9-CMm6kTmd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DieFFehrlasS",
        "outputId": "54aa4fc9-8cba-4f01-bd88-f471f6bd1c16"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_loader:\n",
        "  inputs = {\n",
        "      \"input_ids\": x[\"input_ids\"].to(device),\n",
        "      \"attention_mask\": x[\"attention_masks\"].to(device)\n",
        "  }\n",
        "  out = model(**inputs)\n",
        "  print(out)\n",
        "  print(out.keys)\n",
        "  print(dir(out))\n",
        "  print(out.last_hidden_state.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDWzgyIkPsrQ",
        "outputId": "32a2d135-2ad1-4048-da82-192f1768b4e0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.7560e-01, -1.3228e-01,  1.8230e-01,  ...,  3.2990e-01,\n",
            "          -1.8657e-01,  2.3397e-01],\n",
            "         [-5.9784e-01, -5.7548e-01, -1.7298e-01,  ...,  2.5276e-01,\n",
            "          -3.7177e-01,  3.9954e-01],\n",
            "         [-5.5432e-01, -6.8137e-01, -4.0888e-01,  ...,  3.6149e-01,\n",
            "          -1.5059e-01,  2.4989e-02],\n",
            "         ...,\n",
            "         [-5.7257e-01, -3.1346e-01, -4.2063e-02,  ...,  5.1441e-01,\n",
            "          -2.9025e-01,  3.0190e-01],\n",
            "         [-4.4250e-01, -2.7983e-01,  3.7805e-02,  ...,  4.4907e-01,\n",
            "          -3.3852e-01,  1.7646e-01],\n",
            "         [-4.3435e-01, -3.8130e-01,  1.7972e-01,  ...,  2.5209e-01,\n",
            "          -1.6422e-01,  9.8774e-02]],\n",
            "\n",
            "        [[ 8.8883e-02,  9.2440e-02, -2.0393e-01,  ...,  4.4153e-01,\n",
            "           1.9131e-02,  8.0090e-02],\n",
            "         [-2.3833e-01, -8.5419e-01,  4.8302e-01,  ...,  7.2092e-01,\n",
            "           5.6347e-01,  6.3043e-03],\n",
            "         [-4.9513e-01, -1.0790e+00,  4.5205e-01,  ...,  1.0678e+00,\n",
            "           9.6370e-01,  6.1082e-01],\n",
            "         ...,\n",
            "         [-1.1960e-01,  2.6706e-01,  1.4266e-01,  ..., -3.9065e-02,\n",
            "          -8.5568e-02, -1.0201e-01],\n",
            "         [ 3.1331e-01, -5.9751e-02,  1.2007e+00,  ..., -5.0346e-01,\n",
            "          -2.8314e-02, -3.0198e-01],\n",
            "         [ 1.2822e-01,  4.3939e-01,  5.7046e-01,  ..., -7.8924e-01,\n",
            "           1.7129e-02, -6.7419e-02]],\n",
            "\n",
            "        [[-7.5752e-02, -7.5381e-03, -1.4116e-01,  ...,  4.1303e-01,\n",
            "          -2.6035e-02, -1.3214e-01],\n",
            "         [-4.4965e-01, -3.9341e-01,  2.9171e-01,  ...,  1.0787e+00,\n",
            "           4.9525e-02, -4.5239e-01],\n",
            "         [-3.7624e-01, -3.0663e-01, -1.4125e-01,  ...,  9.0251e-01,\n",
            "          -1.1124e-02,  5.8090e-02],\n",
            "         ...,\n",
            "         [-4.2337e-01,  4.1215e-01,  2.0765e-01,  ...,  1.3573e+00,\n",
            "           4.9461e-01, -1.1208e+00],\n",
            "         [-2.8639e-01,  4.0263e-01,  6.2676e-01,  ...,  6.5061e-01,\n",
            "           2.6887e-01, -5.6514e-01],\n",
            "         [-1.3511e-01, -2.4396e-02,  8.5481e-02,  ...,  5.9691e-01,\n",
            "          -6.2865e-02, -1.6491e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-5.3180e-02,  1.6224e-01, -1.3453e-01,  ...,  9.7788e-02,\n",
            "           2.6402e-01,  5.4028e-02],\n",
            "         [-2.3491e-01,  3.1942e-01,  9.4921e-01,  ...,  8.1319e-01,\n",
            "           2.4949e-01, -3.1641e-02],\n",
            "         [ 2.0553e-01,  5.5366e-01,  8.3173e-01,  ...,  3.0447e-01,\n",
            "          -1.3862e-02,  9.8647e-02],\n",
            "         ...,\n",
            "         [ 2.8510e-01,  7.1617e-01,  5.3532e-01,  ...,  5.9298e-01,\n",
            "          -4.4326e-01,  5.3097e-01],\n",
            "         [ 1.4272e-01, -1.1195e-01, -3.9836e-03,  ...,  2.0200e-01,\n",
            "           2.8142e-01,  7.3501e-01],\n",
            "         [ 3.9241e-01,  3.5570e-01, -5.5569e-01,  ...,  7.1969e-01,\n",
            "          -5.8623e-02, -3.2720e-02]],\n",
            "\n",
            "        [[-1.9916e-01, -1.7328e-01, -4.0953e-01,  ...,  4.0955e-01,\n",
            "           3.2062e-01, -3.4935e-02],\n",
            "         [-7.3906e-01,  4.4172e-02,  2.7742e-01,  ...,  8.8932e-01,\n",
            "           6.1824e-01,  2.6101e-01],\n",
            "         [-4.6135e-01, -4.6557e-02, -1.0826e+00,  ...,  1.1039e+00,\n",
            "           4.9900e-01,  5.2507e-02],\n",
            "         ...,\n",
            "         [-3.0461e-01, -4.1836e-02, -2.5648e-01,  ...,  1.0950e-01,\n",
            "           3.5850e-01,  1.9045e-01],\n",
            "         [-3.8103e-01, -5.3987e-02, -2.8789e-01,  ...,  4.2734e-01,\n",
            "           2.6518e-01,  1.4980e-01],\n",
            "         [-9.7235e-02,  1.5091e-01, -6.6771e-01,  ...,  2.5567e-01,\n",
            "           9.1244e-02,  2.3024e-01]],\n",
            "\n",
            "        [[-2.3609e-01, -1.4937e-01, -6.9915e-02,  ...,  2.3793e-01,\n",
            "           1.3933e-01,  3.0693e-02],\n",
            "         [-3.0797e-01, -5.8360e-01, -3.4977e-01,  ...,  6.1812e-01,\n",
            "           1.1276e-01,  3.0346e-01],\n",
            "         [ 7.6089e-02, -6.2828e-01,  8.6584e-01,  ..., -1.0561e-01,\n",
            "          -1.1990e-01,  2.7582e-01],\n",
            "         ...,\n",
            "         [-5.8358e-01, -3.5570e-01,  3.3639e-01,  ...,  3.2995e-01,\n",
            "          -3.6680e-01,  8.3908e-01],\n",
            "         [-6.0236e-01, -2.9472e-01,  2.6431e-01,  ...,  2.4208e-01,\n",
            "           7.9832e-02,  2.2216e-01],\n",
            "         [-5.7147e-01, -2.1606e-01,  2.0091e-01,  ...,  3.7511e-01,\n",
            "          -5.8205e-02,  1.0196e-03]]], device='cuda:0',\n",
            "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2571, -0.1477,  0.3254,  ..., -0.1625,  0.2980,  0.2556],\n",
            "        [ 0.3658, -0.2213,  0.3618,  ..., -0.4435,  0.2875,  0.3892],\n",
            "        [ 0.1314, -0.0584,  0.1785,  ..., -0.1465, -0.0490,  0.1010],\n",
            "        ...,\n",
            "        [ 0.0967, -0.0853,  0.1257,  ..., -0.1001,  0.0311,  0.1487],\n",
            "        [ 0.5040, -0.3440,  0.2539,  ..., -0.4675,  0.3183,  0.4859],\n",
            "        [ 0.2413, -0.0306,  0.1037,  ..., -0.3198,  0.1024,  0.1571]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
            "<built-in method keys of BaseModelOutputWithPoolingAndCrossAttentions object at 0x791061a4c040>\n",
            "['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'cross_attentions', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'last_hidden_state', 'move_to_end', 'past_key_values', 'pooler_output', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n",
            "torch.Size([16, 67, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self, bert_model):\n",
        "    super().__init__()\n",
        "    self.bert_model = bert_model\n",
        "    self.fc1 = nn.Linear(768, 3)\n",
        "\n",
        "\n",
        "  def forward(self, inputs, labels=None):\n",
        "    out = self.bert_model(**inputs)\n",
        "    last_hidden_states = out.last_hidden_state # (B, T, 768)\n",
        "\n",
        "    cls_logits = last_hidden_states[:, 0, :] # (B, 768)\n",
        "    logits = self.fc1(cls_logits) # (B, 3)\n",
        "\n",
        "    loss = None\n",
        "\n",
        "    if labels is not None:\n",
        "      loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "    return logits, loss"
      ],
      "metadata": {
        "id": "M_K_ViH2n6G3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_model = BERTClassifier(bert_model = model)\n",
        "cls_model.to(device)\n",
        "learning_rate = 2e-5\n",
        "optimizer = torch.optim.AdamW(cls_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "VQDcLdi9tIWR"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVein34VwIdf",
        "outputId": "1236dc2b-a6d1-43ef-afd2-7726137f814b"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hei1u3NEwaPl",
        "outputId": "fdb12e7c-e7f5-4b40-d675-a1868aaa0123"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x790f7813c920>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"dear-watson\", config={\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"epochs\": 2,\n",
        "    \"batch_size\": train_loader.batch_size,\n",
        "})\n",
        "\n",
        "\n",
        "iter_idx = 0\n",
        "print_every = 20\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  total_epoch_loss = 0\n",
        "  total_epoch_samples = 0\n",
        "\n",
        "  cls_model.train()\n",
        "\n",
        "  for batch in train_loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_masks\"].to(device)\n",
        "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "\n",
        "    inputs = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "    logits, loss = cls_model(inputs, labels=labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    num_correct = torch.sum((preds == labels).to(torch.int))\n",
        "\n",
        "\n",
        "    total_epoch_loss += loss.item() * len(labels)\n",
        "    total_epoch_samples += len(labels)\n",
        "\n",
        "    # Log batch metrics to wandb\n",
        "    wandb.log({\"train/loss\": loss.item(), \"train/acc\": num_correct.item() / len(preds), \"epoch\": i, \"iteration\": iter_idx,})\n",
        "\n",
        "    if iter_idx % print_every == 0:\n",
        "      print(f\"Iteration: {iter_idx}: Loss: {loss.item()}, Acc: {num_correct.item() / len(preds)}\")\n",
        "\n",
        "    iter_idx += 1\n",
        "\n",
        "  print(f\"Epoch {i} Avg Loss - {total_epoch_loss / total_epoch_samples}\")\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_wZAj-muk3le",
        "outputId": "3fd382ed-15be-4b62-c12a-4fe2409e6034"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██████████</td></tr><tr><td>iteration</td><td>▁▁▁▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/acc</td><td>▂▄▅▄▄█▁▅▅▂▅▅▅▃▅▃▅▃▃▅▃▅▂▄▄▃▄▅▃▄▆▅▅▄▁▃▄▆▅▃</td></tr><tr><td>train/loss</td><td>▅█▅█▅█▃▅▅▄▅▁▆▃▂▃▆▅▄▂▄▃▇▅▄▃▄▇▂▄▆▂▄▄▂▃▃▇▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>iteration</td><td>1040</td></tr><tr><td>train/acc</td><td>0.3125</td></tr><tr><td>train/loss</td><td>1.1227</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">solar-smoke-5</strong> at: <a href='https://wandb.ai/saahith/dear-watson/runs/4hcree7q' target=\"_blank\">https://wandb.ai/saahith/dear-watson/runs/4hcree7q</a><br> View project at: <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">https://wandb.ai/saahith/dear-watson</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251107_054605-4hcree7q/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251107_055207-65vunkei</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saahith/dear-watson/runs/65vunkei' target=\"_blank\">rosy-pine-6</a></strong> to <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">https://wandb.ai/saahith/dear-watson</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saahith/dear-watson/runs/65vunkei' target=\"_blank\">https://wandb.ai/saahith/dear-watson/runs/65vunkei</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0: Loss: 1.0752451419830322, Acc: 0.4375\n",
            "Iteration: 20: Loss: 1.0942145586013794, Acc: 0.25\n",
            "Iteration: 40: Loss: 1.086463451385498, Acc: 0.4375\n",
            "Iteration: 60: Loss: 1.1408863067626953, Acc: 0.25\n",
            "Iteration: 80: Loss: 1.1121437549591064, Acc: 0.375\n",
            "Iteration: 100: Loss: 0.9233945608139038, Acc: 0.4375\n",
            "Iteration: 120: Loss: 1.285954475402832, Acc: 0.375\n",
            "Iteration: 140: Loss: 1.0916023254394531, Acc: 0.5\n",
            "Iteration: 160: Loss: 0.8810546398162842, Acc: 0.6875\n",
            "Iteration: 180: Loss: 0.8863829374313354, Acc: 0.5\n",
            "Iteration: 200: Loss: 0.6846553087234497, Acc: 0.8125\n",
            "Iteration: 220: Loss: 0.8127942681312561, Acc: 0.5\n",
            "Iteration: 240: Loss: 0.7697547674179077, Acc: 0.6875\n",
            "Iteration: 260: Loss: 1.1187448501586914, Acc: 0.4375\n",
            "Iteration: 280: Loss: 0.7714827060699463, Acc: 0.75\n",
            "Iteration: 300: Loss: 0.7542095184326172, Acc: 0.625\n",
            "Iteration: 320: Loss: 0.8546866178512573, Acc: 0.625\n",
            "Iteration: 340: Loss: 0.6489604115486145, Acc: 0.625\n",
            "Iteration: 360: Loss: 0.8856885433197021, Acc: 0.625\n",
            "Iteration: 380: Loss: 0.7612470388412476, Acc: 0.6875\n",
            "Iteration: 400: Loss: 1.1419868469238281, Acc: 0.4375\n",
            "Iteration: 420: Loss: 0.7934705018997192, Acc: 0.6875\n",
            "Iteration: 440: Loss: 0.688152551651001, Acc: 0.75\n",
            "Iteration: 460: Loss: 1.06882905960083, Acc: 0.5\n",
            "Iteration: 480: Loss: 0.9082610607147217, Acc: 0.6875\n",
            "Iteration: 500: Loss: 0.7692267894744873, Acc: 0.625\n",
            "Iteration: 520: Loss: 0.7846946120262146, Acc: 0.6875\n",
            "Iteration: 540: Loss: 0.8978752493858337, Acc: 0.4375\n",
            "Iteration: 560: Loss: 1.4943652153015137, Acc: 0.375\n",
            "Iteration: 580: Loss: 0.8902856707572937, Acc: 0.5625\n",
            "Iteration: 600: Loss: 0.7756894826889038, Acc: 0.625\n",
            "Iteration: 620: Loss: 0.9047896862030029, Acc: 0.5\n",
            "Iteration: 640: Loss: 0.9294348955154419, Acc: 0.625\n",
            "Iteration: 660: Loss: 0.875234842300415, Acc: 0.6875\n",
            "Iteration: 680: Loss: 0.7491269111633301, Acc: 0.6875\n",
            "Iteration: 700: Loss: 0.8272756934165955, Acc: 0.625\n",
            "Iteration: 720: Loss: 1.230460286140442, Acc: 0.625\n",
            "Iteration: 740: Loss: 0.9044327139854431, Acc: 0.5625\n",
            "Epoch 0 Avg Loss - 0.9041818349274865\n",
            "Iteration: 760: Loss: 0.4354780912399292, Acc: 0.8125\n",
            "Iteration: 780: Loss: 0.7842812538146973, Acc: 0.625\n",
            "Iteration: 800: Loss: 0.7607042789459229, Acc: 0.6875\n",
            "Iteration: 820: Loss: 0.5176725387573242, Acc: 0.8125\n",
            "Iteration: 840: Loss: 0.6949462294578552, Acc: 0.6875\n",
            "Iteration: 860: Loss: 0.5134016275405884, Acc: 0.8125\n",
            "Iteration: 880: Loss: 0.6854937076568604, Acc: 0.75\n",
            "Iteration: 900: Loss: 0.5899997353553772, Acc: 0.75\n",
            "Iteration: 920: Loss: 0.6729583740234375, Acc: 0.6875\n",
            "Iteration: 940: Loss: 0.5371400117874146, Acc: 0.75\n",
            "Iteration: 960: Loss: 0.5326336622238159, Acc: 0.9375\n",
            "Iteration: 980: Loss: 0.5201820135116577, Acc: 0.875\n",
            "Iteration: 1000: Loss: 0.8706226944923401, Acc: 0.625\n",
            "Iteration: 1020: Loss: 0.8923619985580444, Acc: 0.75\n",
            "Iteration: 1040: Loss: 0.4463766813278198, Acc: 0.9375\n",
            "Iteration: 1060: Loss: 0.607451319694519, Acc: 0.6875\n",
            "Iteration: 1080: Loss: 0.7911916375160217, Acc: 0.6875\n",
            "Iteration: 1100: Loss: 0.9448527097702026, Acc: 0.625\n",
            "Iteration: 1120: Loss: 0.609234094619751, Acc: 0.75\n",
            "Iteration: 1140: Loss: 0.779755711555481, Acc: 0.6875\n",
            "Iteration: 1160: Loss: 0.5959113836288452, Acc: 0.75\n",
            "Iteration: 1180: Loss: 0.6591283679008484, Acc: 0.625\n",
            "Iteration: 1200: Loss: 0.7119288444519043, Acc: 0.75\n",
            "Iteration: 1220: Loss: 0.7612690329551697, Acc: 0.875\n",
            "Iteration: 1240: Loss: 0.8527688980102539, Acc: 0.5625\n",
            "Iteration: 1260: Loss: 0.4475643038749695, Acc: 0.75\n",
            "Iteration: 1280: Loss: 0.6586552858352661, Acc: 0.8125\n",
            "Iteration: 1300: Loss: 0.5428268313407898, Acc: 0.75\n",
            "Iteration: 1320: Loss: 0.924202561378479, Acc: 0.5625\n",
            "Iteration: 1340: Loss: 0.44803115725517273, Acc: 0.875\n",
            "Iteration: 1360: Loss: 1.001064658164978, Acc: 0.75\n",
            "Iteration: 1380: Loss: 0.5932105779647827, Acc: 0.75\n",
            "Iteration: 1400: Loss: 0.4707251191139221, Acc: 0.875\n",
            "Iteration: 1420: Loss: 0.736669659614563, Acc: 0.6875\n",
            "Iteration: 1440: Loss: 0.4453931152820587, Acc: 0.8125\n",
            "Iteration: 1460: Loss: 0.505580484867096, Acc: 0.875\n",
            "Iteration: 1480: Loss: 0.4917370676994324, Acc: 0.75\n",
            "Iteration: 1500: Loss: 0.6390836238861084, Acc: 0.75\n",
            "Epoch 1 Avg Loss - 0.6619597793018858\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>iteration</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▄▅▅▅▅▅▅▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/acc</td><td>▁▂▃▂▂▆▅▂▅▄▂▂▄▅▆▅▃▅▆▄▇▇▅█▇▄▂▆█▇▅▇▅▅▁▇▅▆▇▅</td></tr><tr><td>train/loss</td><td>█▇█▆▇▆▅▆▆▇▇▄▄▆▆▄▅▄▅▄▅▇▄▄▂▃▄▃▇▅▁▃▁▄▃▄▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>iteration</td><td>1515</td></tr><tr><td>train/acc</td><td>0.75</td></tr><tr><td>train/loss</td><td>0.56562</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">rosy-pine-6</strong> at: <a href='https://wandb.ai/saahith/dear-watson/runs/65vunkei' target=\"_blank\">https://wandb.ai/saahith/dear-watson/runs/65vunkei</a><br> View project at: <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">https://wandb.ai/saahith/dear-watson</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251107_055207-65vunkei/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "all_preds = []\n",
        "all_ids = []\n",
        "\n",
        "cls_model.eval()\n",
        "\n",
        "for batch in test_loader:\n",
        "\n",
        "  with torch.no_grad():\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_masks\"].to(device)\n",
        "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "\n",
        "    inputs = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    ids = batch[\"ids\"]\n",
        "\n",
        "    logits, _ = cls_model(inputs)\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    preds = preds.tolist()\n",
        "\n",
        "    all_preds += preds\n",
        "    all_ids += ids"
      ],
      "metadata": {
        "id": "ZyUJULShnVDe"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the collected IDs and predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    \"id\": all_ids,\n",
        "    \"prediction\": all_preds\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file, index=False is required by Kaggle\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Submission file created successfully!\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOBV30Y_5TZd",
        "outputId": "53beca32-7b00-4512-a010-4a37d4988b6d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created successfully!\n",
            "           id  prediction\n",
            "0  c6d58c3f69           2\n",
            "1  cefcc82292           1\n",
            "2  e98005252c           0\n",
            "3  58518c10ba           1\n",
            "4  c32b0d16df           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8Q_QtCy6A5n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}