{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "xtvSmSjwvULV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "\n",
        "print(model)\n",
        "print(\"---------------\")\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t1MVf-gvmjD",
        "outputId": "29a732df-193b-4cb0-f127-8b35a9befad7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0-11): 12 x BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSdpaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n",
            "---------------\n",
            "BertTokenizer(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True, added_tokens_decoder={\n",
            "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlADoi9LvsbO",
        "outputId": "7599b084-4689-48a1-d06f-017524c86b49"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('csv', data_files='/content/drive/MyDrive/contradictory-my-dear-watson/data/train.csv')\n",
        "test_dataset = load_dataset('csv',  data_files='/content/drive/MyDrive/contradictory-my-dear-watson/data/test.csv')"
      ],
      "metadata": {
        "id": "6tlKv6D6v1ni"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ag9l7fZxq2V",
        "outputId": "ae8052a2-acda-4ebe-c29c-242b939f6b64"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'premise', 'hypothesis', 'lang_abv', 'language', 'label'],\n",
              "        num_rows: 12120\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efhGTsTGxy02",
        "outputId": "11797670-c5aa-41b6-9396-deec649f9a1a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': '5130fd2cb5', 'premise': 'and these comments were considered in formulating the interim rules.', 'hypothesis': 'The rules developed in the interim were put together with these comments in mind.', 'lang_abv': 'en', 'language': 'English', 'label': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDphDqx3xr0Y",
        "outputId": "45b8e458-ef28-400a-8b76-0cc2d3c4c93b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'premise', 'hypothesis', 'lang_abv', 'language'],\n",
              "        num_rows: 5195\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the training dataset into train/validation\n",
        "split_dataset = train_dataset['train'].train_test_split(\n",
        "    test_size=0.1,   # 10% for validation (adjust as needed)\n",
        "    seed=42,         # ensures reproducibility\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "train_ds_orig = split_dataset['train']\n",
        "val_ds_orig = split_dataset['test']"
      ],
      "metadata": {
        "id": "qSPB2oA2_Cb5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset['train'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQQiZn1JwcEI",
        "outputId": "271fa311-ab23-4321-d075-f902e122ad7d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 'cefcc82292', 'premise': 'هذا هو ما تم نصحنا به.', 'hypothesis': 'عندما يتم إخبارهم بما يجب عليهم فعله ، فشلت الإدارة في السماح لنا بالدخول إلى الأسرار التجارية.', 'lang_abv': 'ar', 'language': 'Arabic'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "FFvFJemOw_VQ",
        "outputId": "00c3d711-f7c5-49d4-b15e-f673aad7a77b"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 691);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"[CLS] hi ther\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeyUNSP5UCin",
        "outputId": "de99b025-0e2c-4413-cc65-276808ac8cdc"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 101, 11520, 10105, 10129, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lU0eALVVuRX",
        "outputId": "a95b3158-4a23-4427-daea-cd73370e90cb"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SPECIAL_TOKENS_ATTRIBUTES',\n",
              " '__annotations__',\n",
              " '__call__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattr__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_add_tokens',\n",
              " '_added_tokens_decoder',\n",
              " '_added_tokens_encoder',\n",
              " '_auto_class',\n",
              " '_batch_encode_plus',\n",
              " '_batch_prepare_for_model',\n",
              " '_call_one',\n",
              " '_convert_id_to_token',\n",
              " '_convert_token_to_id',\n",
              " '_convert_token_to_id_with_added_voc',\n",
              " '_create_repo',\n",
              " '_decode',\n",
              " '_decode_use_source_tokenizer',\n",
              " '_encode_plus',\n",
              " '_eventual_warn_about_too_long_sequence',\n",
              " '_eventually_correct_t5_max_length',\n",
              " '_from_pretrained',\n",
              " '_get_files_timestamps',\n",
              " '_get_padding_truncation_strategies',\n",
              " '_in_target_context_manager',\n",
              " '_pad',\n",
              " '_pad_token_type_id',\n",
              " '_processor_class',\n",
              " '_save_pretrained',\n",
              " '_set_model_specific_special_tokens',\n",
              " '_set_processor_class',\n",
              " '_special_tokens_map',\n",
              " '_switch_to_input_mode',\n",
              " '_switch_to_target_mode',\n",
              " '_tokenize',\n",
              " '_update_total_vocab_size',\n",
              " '_update_trie',\n",
              " '_upload_modified_files',\n",
              " 'add_special_tokens',\n",
              " 'add_tokens',\n",
              " 'added_tokens_decoder',\n",
              " 'added_tokens_encoder',\n",
              " 'all_special_ids',\n",
              " 'all_special_tokens',\n",
              " 'all_special_tokens_extended',\n",
              " 'apply_chat_template',\n",
              " 'as_target_tokenizer',\n",
              " 'basic_tokenizer',\n",
              " 'batch_decode',\n",
              " 'batch_encode_plus',\n",
              " 'build_inputs_with_special_tokens',\n",
              " 'chat_template',\n",
              " 'clean_up_tokenization',\n",
              " 'clean_up_tokenization_spaces',\n",
              " 'convert_added_tokens',\n",
              " 'convert_ids_to_tokens',\n",
              " 'convert_tokens_to_ids',\n",
              " 'convert_tokens_to_string',\n",
              " 'create_token_type_ids_from_sequences',\n",
              " 'decode',\n",
              " 'deprecation_warnings',\n",
              " 'do_basic_tokenize',\n",
              " 'do_lower_case',\n",
              " 'encode',\n",
              " 'encode_message_with_chat_template',\n",
              " 'encode_plus',\n",
              " 'extra_special_tokens',\n",
              " 'from_pretrained',\n",
              " 'get_added_vocab',\n",
              " 'get_chat_template',\n",
              " 'get_special_tokens_mask',\n",
              " 'get_vocab',\n",
              " 'ids_to_tokens',\n",
              " 'init_inputs',\n",
              " 'init_kwargs',\n",
              " 'is_fast',\n",
              " 'max_len_sentences_pair',\n",
              " 'max_len_single_sentence',\n",
              " 'model_input_names',\n",
              " 'model_max_length',\n",
              " 'name_or_path',\n",
              " 'num_special_tokens_to_add',\n",
              " 'pad',\n",
              " 'pad_token_type_id',\n",
              " 'padding_side',\n",
              " 'prepare_for_model',\n",
              " 'prepare_for_tokenization',\n",
              " 'prepare_seq2seq_batch',\n",
              " 'pretrained_vocab_files_map',\n",
              " 'push_to_hub',\n",
              " 'register_for_auto_class',\n",
              " 'sanitize_special_tokens',\n",
              " 'save_chat_templates',\n",
              " 'save_pretrained',\n",
              " 'save_vocabulary',\n",
              " 'slow_tokenizer_class',\n",
              " 'special_tokens_map',\n",
              " 'special_tokens_map_extended',\n",
              " 'split_special_tokens',\n",
              " 'tokenize',\n",
              " 'tokens_trie',\n",
              " 'total_vocab_size',\n",
              " 'truncate_sequences',\n",
              " 'truncation_side',\n",
              " 'verbose',\n",
              " 'vocab',\n",
              " 'vocab_files_names',\n",
              " 'vocab_size',\n",
              " 'wordpiece_tokenizer']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(101)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mcjKi325UIRT",
        "outputId": "44d0992a-89bc-4566-b442-e9e46103ec98"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode([101, 101, 11463, 10103, 10131, 102])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6Ufg-x_aULbu",
        "outputId": "25b6ccdf-21b2-4eed-a85c-519ea9f3fa40"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] [CLS] 1925 𩾌 et [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"hello\", \"goodbye\", return_tensors=\"pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4LL-HkJyjri",
        "outputId": "5869de99-2664-4708-99b1-97bc4fc1db8a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 61694, 10133,   102, 15198, 87421,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import unicodedata, re\n",
        "\n",
        "CONTROL_CHARS = (\n",
        "    r\"[\\u200B-\\u200F\\u202A-\\u202E\\u2066-\\u2069\\uFEFF]\"  # ZW*, bidi, BOM\n",
        ")\n",
        "def clean_text(s: str) -> str:\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = re.sub(CONTROL_CHARS, \"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "\n",
        "class WatsonDataset(Dataset):\n",
        "  def __init__(self, ds, is_train=True):\n",
        "    self.ds = ds\n",
        "    self.is_train = is_train\n",
        "\n",
        "  def __getitem__(self, x):\n",
        "    row = self.ds[x]\n",
        "    premise = row['premise']\n",
        "    hypothesis = row['hypothesis']\n",
        "    if self.is_train:\n",
        "      label = torch.tensor(row['label'])\n",
        "    my_id = row[\"id\"]\n",
        "\n",
        "    enc = tokenizer(\n",
        "    clean_text(premise),\n",
        "    clean_text(hypothesis),\n",
        "    return_tensors=\"pt\",\n",
        "    truncation=True)  # add max_length if you want\n",
        "\n",
        "    return_map = {\n",
        "        \"input_ids\": enc[\"input_ids\"][0],\n",
        "        \"attention_mask\": enc[\"attention_mask\"][0],\n",
        "        \"id\": my_id,\n",
        "        \"token_type_ids\": enc[\"token_type_ids\"][0]\n",
        "    }\n",
        "\n",
        "    if self.is_train:\n",
        "      return_map[\"label\"] = label\n",
        "\n",
        "    return return_map\n",
        "\n",
        "\n",
        "  def __len__(self, ):\n",
        "    return len(self.ds)\n"
      ],
      "metadata": {
        "id": "3dzvJpLcSsjt"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = WatsonDataset(train_ds_orig, is_train=True)\n",
        "val_ds = WatsonDataset(val_ds_orig, is_train=True)\n",
        "test_ds = WatsonDataset(test_dataset[\"train\"], is_train=False)\n",
        "\n",
        "# train_ds_orig = split_dataset['train']\n",
        "# val_ds_orig = split_dataset['test']"
      ],
      "metadata": {
        "id": "qTIcoAKQTCX5"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GtLBJFpy_XqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_ds:\n",
        "  print(tokenizer.decode(x['input_ids']))\n",
        "  print(x['attention_mask'])\n",
        "  print(x['label'])\n",
        "  print(x['token_type_ids'])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jtwYM74Vb91",
        "outputId": "b4737300-c524-41ff-e1d3-85005a78fa63"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] There is very little to see here, or at the ruined Essene monastery of Qumran itself. [SEP] Most visitors skip this city, or only stay here a night while passing through. [SEP]\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor(1)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def my_collate_fn(batch):\n",
        "    input_ids = [row['input_ids'] for row in batch]\n",
        "    attention_masks = [row['attention_mask'] for row in batch]\n",
        "    ids = [row['id'] for row in batch]\n",
        "    token_type_ids = [row['token_type_ids'] for row in batch]\n",
        "\n",
        "    if 'label' in batch[0]:\n",
        "      labels = [row['label'] for row in batch]\n",
        "      labels = torch.stack(labels, dim=0)\n",
        "\n",
        "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value = 0)\n",
        "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value = 0)\n",
        "    token_type_ids = pad_sequence(token_type_ids, batch_first=True, padding_value=0)\n",
        "\n",
        "    return_map = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_masks\": attention_masks,\n",
        "        \"ids\": ids,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    if 'label' in batch[0]:\n",
        "      return_map['labels'] = labels\n",
        "\n",
        "    return return_map"
      ],
      "metadata": {
        "id": "VSewz0AOTOQm"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_ds, collate_fn = my_collate_fn, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_ds, collate_fn = my_collate_fn, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "QoUBNbiYcGN4"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_loader:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J74LzrKc3sk",
        "outputId": "d7b08242-45ea-4ae8-e1b3-9a4858408bb7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 11038, 11598,  ...,     0,     0,     0],\n",
            "        [  101, 11518, 35678,  ...,     0,     0,     0],\n",
            "        [  101, 48024, 10213,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101,   433, 34335,  ..., 21263,   119,   102],\n",
            "        [  101,   146, 10529,  ...,     0,     0,     0],\n",
            "        [  101, 10111, 13028,  ...,     0,     0,     0]]), 'attention_masks': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'ids': ['9b65fd470c', '5b47900535', 'd6583f0140', '759a9fed94', '22a006ea5f', '33ef8689bc', '8344360c42', '00cbeb090b', '20e05b72ff', '8b103566f7', 'a241d033c1', 'f97632e514', '87fe8884c3', '0b2466990a', 'a9a9982a67', 'bdfd19af00'], 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'labels': tensor([1, 2, 1, 0, 1, 1, 2, 0, 1, 0, 0, 2, 2, 1, 1, 2])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in test_loader:\n",
        "  print(x)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezBqOo40jL76",
        "outputId": "bed6d439-1073-4cb4-a989-e442e7ba147a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   101,    764,  28744,  ...,  17571,    119,    102],\n",
            "        [   101,  13498,  11917,  ...,      0,      0,      0],\n",
            "        [   101,  10131,  24552,  ...,      0,      0,      0],\n",
            "        ...,\n",
            "        [   101,  26467,    146,  ...,      0,      0,      0],\n",
            "        [   101,    530, 110702,  ...,      0,      0,      0],\n",
            "        [   101,  40690,    117,  ...,      0,      0,      0]]), 'attention_masks': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'ids': ['c6d58c3f69', 'cefcc82292', 'e98005252c', '58518c10ba', 'c32b0d16df', 'aa2510d454', '865d1c7b16', 'a16f7ed56b', '6d9fa191e6', 'c156e8fed5', 'f11f1ffffe', 'd41b559e9f', '40a9b0f08e', 'd8f3da717a', '126e3cfa1b', '4e9266e800'], 'token_type_ids': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "gV9-CMm6kTmd"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DieFFehrlasS",
        "outputId": "b6759587-d376-4193-f2d2-f3153ae46f38"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSdpaSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in train_loader:\n",
        "  inputs = {\n",
        "      \"input_ids\": x[\"input_ids\"].to(device),\n",
        "      \"attention_mask\": x[\"attention_masks\"].to(device)\n",
        "  }\n",
        "  out = model(**inputs)\n",
        "  print(out)\n",
        "  print(out.keys)\n",
        "  print(dir(out))\n",
        "  print(out.last_hidden_state.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDWzgyIkPsrQ",
        "outputId": "3ece2d0c-0e0a-4f9e-fc7c-ac37a21b039d"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-4.9520e-02,  8.7147e-02,  3.8480e-01,  ...,  3.4303e-01,\n",
            "           2.4905e-01, -7.9817e-02],\n",
            "         [-3.1885e-02, -5.1354e-02,  1.2928e+00,  ...,  5.2316e-01,\n",
            "           2.6720e-01, -2.3902e-01],\n",
            "         [-2.9715e-01, -1.5136e-01,  1.1765e+00,  ...,  6.2498e-01,\n",
            "           5.5931e-02, -1.5215e-01],\n",
            "         ...,\n",
            "         [-6.7093e-02,  1.1202e-01,  1.0680e-01,  ...,  1.6604e-01,\n",
            "           4.4419e-01,  2.8469e-01],\n",
            "         [-2.1971e-01, -6.8734e-02,  6.4791e-01,  ...,  3.3016e-01,\n",
            "           2.4431e-01,  1.1911e-03],\n",
            "         [-3.5793e-01, -2.0536e-01,  9.3364e-01,  ...,  4.3020e-01,\n",
            "           3.3514e-01, -1.4544e-01]],\n",
            "\n",
            "        [[ 5.9756e-02,  2.3982e-02,  1.2053e-01,  ...,  2.7593e-01,\n",
            "           2.7395e-01, -1.2928e-01],\n",
            "         [ 2.3343e-01, -3.3693e-01,  5.4048e-01,  ...,  7.4439e-01,\n",
            "           1.5109e-01, -1.0755e-01],\n",
            "         [-4.0765e-01, -2.5708e-02,  1.0377e+00,  ...,  7.7396e-01,\n",
            "           2.0278e-01,  2.9191e-01],\n",
            "         ...,\n",
            "         [-9.1759e-02,  2.6620e-02,  4.0854e-01,  ...,  2.2926e-01,\n",
            "           4.2602e-01, -1.1963e-01],\n",
            "         [-3.3907e-01, -1.5884e-01,  5.6367e-01,  ...,  1.1317e-01,\n",
            "           2.8541e-01, -3.5059e-01],\n",
            "         [-3.3591e-01, -1.2614e-01,  3.0286e-01,  ...,  9.2337e-02,\n",
            "           3.5187e-01, -2.2267e-01]],\n",
            "\n",
            "        [[ 7.6615e-02, -1.1678e-01, -2.1840e-01,  ...,  3.1221e-01,\n",
            "           1.4135e-01,  2.1931e-01],\n",
            "         [-5.2199e-01, -4.4848e-01,  3.2305e-01,  ...,  1.1132e+00,\n",
            "          -2.8991e-02,  3.6216e-01],\n",
            "         [-7.0355e-01,  3.0140e-02,  3.6463e-01,  ...,  6.7319e-01,\n",
            "           1.8156e-01,  7.9161e-01],\n",
            "         ...,\n",
            "         [-3.1196e-01, -3.9325e-01,  3.7158e-01,  ...,  4.2397e-01,\n",
            "          -3.4788e-02,  5.7623e-02],\n",
            "         [-2.8140e-01, -2.7475e-01,  3.5504e-02,  ...,  3.2127e-01,\n",
            "          -1.0661e-01,  4.4815e-01],\n",
            "         [-4.9156e-01,  1.6893e-01,  2.2766e-02,  ...,  3.7800e-01,\n",
            "          -3.2537e-01,  2.8569e-01]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.2179e-01, -7.4801e-02, -4.3045e-01,  ...,  1.5806e-01,\n",
            "           1.6050e-01, -2.2880e-01],\n",
            "         [ 4.5395e-01, -8.9692e-01, -4.0514e-02,  ...,  4.7516e-01,\n",
            "           2.8244e-01, -1.2969e-01],\n",
            "         [-1.5462e-01, -7.7882e-01, -7.1546e-01,  ...,  8.5184e-01,\n",
            "           1.4418e-01, -2.3809e-01],\n",
            "         ...,\n",
            "         [ 1.3223e-01, -1.6547e-01, -3.4030e-01,  ..., -2.5246e-01,\n",
            "           4.5529e-01, -5.3185e-02],\n",
            "         [ 3.1130e-01, -1.1174e-02, -2.2750e-01,  ..., -4.9902e-01,\n",
            "           3.6477e-01, -1.7467e-01],\n",
            "         [ 2.1261e-01, -3.2387e-01, -9.1560e-02,  ..., -5.3982e-01,\n",
            "           3.1224e-01, -2.7191e-01]],\n",
            "\n",
            "        [[-1.4526e-01,  1.6086e-02, -2.3546e-01,  ...,  1.8698e-01,\n",
            "           1.8319e-01,  2.1281e-01],\n",
            "         [-4.8811e-01, -6.0880e-01,  1.6308e-02,  ...,  3.9237e-01,\n",
            "           8.4011e-01,  5.4866e-01],\n",
            "         [-2.7174e-01, -6.8876e-01, -1.7840e-01,  ...,  2.2939e-01,\n",
            "           2.8854e-01,  8.1197e-01],\n",
            "         ...,\n",
            "         [-5.6930e-02,  1.0207e-01,  8.8103e-02,  ...,  8.4025e-02,\n",
            "           4.9258e-02,  2.0397e-01],\n",
            "         [-2.3188e-01,  7.1786e-03,  2.4219e-02,  ..., -3.4134e-02,\n",
            "           3.7675e-01,  4.1091e-01],\n",
            "         [ 3.2539e-01, -9.5024e-02,  1.0974e+00,  ..., -3.8042e-01,\n",
            "           2.2204e-01,  2.3181e-01]],\n",
            "\n",
            "        [[-8.9325e-02, -2.8771e-02, -1.9770e-01,  ...,  4.2088e-03,\n",
            "           4.7173e-01, -1.3722e-01],\n",
            "         [-7.2565e-02, -2.4733e-01,  3.5308e-01,  ...,  2.4735e-01,\n",
            "           1.0006e+00, -2.5318e-01],\n",
            "         [-2.2590e-01, -1.9500e-01,  2.6838e-01,  ...,  2.6270e-01,\n",
            "           1.0260e+00, -4.5196e-01],\n",
            "         ...,\n",
            "         [-1.6021e-01, -1.2644e-01,  2.6982e-01,  ..., -2.9270e-01,\n",
            "           4.9067e-01,  1.5479e-01],\n",
            "         [-2.0324e-01,  1.3258e-02,  1.0844e-01,  ..., -2.1650e-01,\n",
            "           5.4454e-01,  1.9466e-01],\n",
            "         [-3.6704e-01, -2.9256e-02,  1.9591e-01,  ..., -3.4668e-01,\n",
            "           5.8541e-01,  4.6011e-02]]], device='cuda:0',\n",
            "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.2234, -0.0899,  0.0881,  ..., -0.3920,  0.2848,  0.3437],\n",
            "        [ 0.0247, -0.0697,  0.3027,  ..., -0.2873,  0.2221,  0.1941],\n",
            "        [ 0.4183, -0.0351,  0.2533,  ..., -0.2271,  0.3181,  0.1906],\n",
            "        ...,\n",
            "        [ 0.1293, -0.1558,  0.2593,  ..., -0.3564,  0.2229,  0.1842],\n",
            "        [ 0.3430, -0.0706,  0.1852,  ..., -0.3608,  0.2305,  0.2265],\n",
            "        [ 0.2487, -0.0850,  0.1820,  ..., -0.2655,  0.1915,  0.2771]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n",
            "<built-in method keys of BaseModelOutputWithPoolingAndCrossAttentions object at 0x79106d8b1bc0>\n",
            "['__annotations__', '__class__', '__class_getitem__', '__contains__', '__dataclass_fields__', '__dataclass_params__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__ior__', '__iter__', '__le__', '__len__', '__lt__', '__match_args__', '__module__', '__ne__', '__new__', '__or__', '__post_init__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__ror__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'attentions', 'clear', 'copy', 'cross_attentions', 'fromkeys', 'get', 'hidden_states', 'items', 'keys', 'last_hidden_state', 'move_to_end', 'past_key_values', 'pooler_output', 'pop', 'popitem', 'setdefault', 'to_tuple', 'update', 'values']\n",
            "torch.Size([16, 100, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self, bert_model):\n",
        "    super().__init__()\n",
        "    self.bert_model = bert_model\n",
        "    self.fc1 = nn.Linear(768, 3)\n",
        "\n",
        "\n",
        "  def forward(self, inputs, labels=None):\n",
        "    out = self.bert_model(**inputs)\n",
        "    last_hidden_states = out.last_hidden_state # (B, T, 768)\n",
        "\n",
        "    cls_logits = last_hidden_states[:, 0, :] # (B, 768)\n",
        "    logits = self.fc1(cls_logits) # (B, 3)\n",
        "\n",
        "    loss = None\n",
        "\n",
        "    if labels is not None:\n",
        "      loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "    return logits, loss"
      ],
      "metadata": {
        "id": "M_K_ViH2n6G3"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_model = BERTClassifier(bert_model = model)\n",
        "cls_model.to(device)\n",
        "learning_rate = 2e-5\n",
        "optimizer = torch.optim.AdamW(cls_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "VQDcLdi9tIWR"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVein34VwIdf",
        "outputId": "69b66451-998c-4aee-e484-d3c885ba34df"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.43.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hei1u3NEwaPl",
        "outputId": "112a4d82-4a02-4c43-f148-4c9ea588d5a4"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x79106cc9d610>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "\n",
        "# Initialize wandb\n",
        "wandb.init(project=\"dear-watson\", config={\n",
        "    \"learning_rate\": 2e-5,\n",
        "    \"epochs\": 2,\n",
        "    \"batch_size\": train_loader.batch_size,\n",
        "})\n",
        "\n",
        "\n",
        "iter_idx = 0\n",
        "print_every = 20\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  total_epoch_loss = 0\n",
        "  total_epoch_samples = 0\n",
        "\n",
        "  cls_model.train()\n",
        "\n",
        "  for batch in train_loader:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_masks\"].to(device)\n",
        "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "\n",
        "    inputs = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "    logits, loss = cls_model(inputs, labels=labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    num_correct = torch.sum((preds == labels).to(torch.int))\n",
        "\n",
        "\n",
        "    total_epoch_loss += loss.item() * len(labels)\n",
        "    total_epoch_samples += len(labels)\n",
        "\n",
        "    # Log batch metrics to wandb\n",
        "    wandb.log({\"train/loss\": loss.item(), \"train/acc\": num_correct.item() / len(preds), \"epoch\": i, \"iteration\": iter_idx,})\n",
        "\n",
        "    if iter_idx % print_every == 0:\n",
        "      print(f\"Iteration: {iter_idx}: Loss: {loss.item()}, Acc: {num_correct.item() / len(preds)}\")\n",
        "\n",
        "    iter_idx += 1\n",
        "\n",
        "  print(f\"Epoch {i} Avg Loss - {total_epoch_loss / total_epoch_samples}\")\n",
        "\n",
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_wZAj-muk3le",
        "outputId": "1dc3909e-1dfd-4466-9fe7-44de72c88b83"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251107_062512-ceqkkjm6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/saahith/dear-watson/runs/ceqkkjm6' target=\"_blank\">eager-elevator-7</a></strong> to <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">https://wandb.ai/saahith/dear-watson</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/saahith/dear-watson/runs/ceqkkjm6' target=\"_blank\">https://wandb.ai/saahith/dear-watson/runs/ceqkkjm6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0: Loss: 1.1780190467834473, Acc: 0.5625\n",
            "Iteration: 20: Loss: 1.051102876663208, Acc: 0.5625\n",
            "Iteration: 40: Loss: 1.1128668785095215, Acc: 0.3125\n",
            "Iteration: 60: Loss: 1.0722763538360596, Acc: 0.5\n",
            "Iteration: 80: Loss: 1.1789867877960205, Acc: 0.125\n",
            "Iteration: 100: Loss: 0.9971007108688354, Acc: 0.4375\n",
            "Iteration: 120: Loss: 0.8047305345535278, Acc: 0.5625\n",
            "Iteration: 140: Loss: 0.9732906222343445, Acc: 0.625\n",
            "Iteration: 160: Loss: 1.0280616283416748, Acc: 0.4375\n",
            "Iteration: 180: Loss: 0.9129911661148071, Acc: 0.625\n",
            "Iteration: 200: Loss: 1.0404412746429443, Acc: 0.5\n",
            "Iteration: 220: Loss: 0.9676237106323242, Acc: 0.5625\n",
            "Iteration: 240: Loss: 1.041637897491455, Acc: 0.4375\n",
            "Iteration: 260: Loss: 0.9177455902099609, Acc: 0.5\n",
            "Iteration: 280: Loss: 0.8575594425201416, Acc: 0.5625\n",
            "Iteration: 300: Loss: 1.0779688358306885, Acc: 0.5625\n",
            "Iteration: 320: Loss: 0.8968088626861572, Acc: 0.4375\n",
            "Iteration: 340: Loss: 0.883427083492279, Acc: 0.625\n",
            "Iteration: 360: Loss: 0.8674348592758179, Acc: 0.5625\n",
            "Iteration: 380: Loss: 0.7884639501571655, Acc: 0.5\n",
            "Iteration: 400: Loss: 0.9921182990074158, Acc: 0.5\n",
            "Iteration: 420: Loss: 0.911663293838501, Acc: 0.6875\n",
            "Iteration: 440: Loss: 0.7712897062301636, Acc: 0.75\n",
            "Iteration: 460: Loss: 1.135138750076294, Acc: 0.4375\n",
            "Iteration: 480: Loss: 1.033110499382019, Acc: 0.625\n",
            "Iteration: 500: Loss: 0.8350481986999512, Acc: 0.75\n",
            "Iteration: 520: Loss: 0.8742704391479492, Acc: 0.5625\n",
            "Iteration: 540: Loss: 0.7283966541290283, Acc: 0.75\n",
            "Iteration: 560: Loss: 0.812158465385437, Acc: 0.5625\n",
            "Iteration: 580: Loss: 0.8253776431083679, Acc: 0.5625\n",
            "Iteration: 600: Loss: 1.0675790309906006, Acc: 0.5\n",
            "Iteration: 620: Loss: 0.9919818043708801, Acc: 0.5\n",
            "Iteration: 640: Loss: 0.7239711284637451, Acc: 0.625\n",
            "Iteration: 660: Loss: 0.7924854755401611, Acc: 0.625\n",
            "Iteration: 680: Loss: 0.7474033832550049, Acc: 0.625\n",
            "Epoch 0 Avg Loss - 0.8889257780002682\n",
            "Iteration: 700: Loss: 0.3996206521987915, Acc: 0.875\n",
            "Iteration: 720: Loss: 0.49546682834625244, Acc: 0.8125\n",
            "Iteration: 740: Loss: 1.0557061433792114, Acc: 0.4375\n",
            "Iteration: 760: Loss: 0.3762626051902771, Acc: 0.9375\n",
            "Iteration: 780: Loss: 1.0325829982757568, Acc: 0.6875\n",
            "Iteration: 800: Loss: 0.4506315588951111, Acc: 0.8125\n",
            "Iteration: 820: Loss: 0.5424209237098694, Acc: 0.8125\n",
            "Iteration: 840: Loss: 0.4885327219963074, Acc: 0.8125\n",
            "Iteration: 860: Loss: 0.6255345940589905, Acc: 0.6875\n",
            "Iteration: 880: Loss: 0.8587938547134399, Acc: 0.625\n",
            "Iteration: 900: Loss: 0.44569557905197144, Acc: 0.8125\n",
            "Iteration: 920: Loss: 0.6001001596450806, Acc: 0.8125\n",
            "Iteration: 940: Loss: 0.9418371915817261, Acc: 0.625\n",
            "Iteration: 960: Loss: 0.6652294397354126, Acc: 0.75\n",
            "Iteration: 980: Loss: 0.6207873225212097, Acc: 0.6875\n",
            "Iteration: 1000: Loss: 0.5373959541320801, Acc: 0.8125\n",
            "Iteration: 1020: Loss: 0.45652252435684204, Acc: 0.625\n",
            "Iteration: 1040: Loss: 0.5277724266052246, Acc: 0.75\n",
            "Iteration: 1060: Loss: 0.4938204884529114, Acc: 0.75\n",
            "Iteration: 1080: Loss: 0.8524698615074158, Acc: 0.625\n",
            "Iteration: 1100: Loss: 0.7024387121200562, Acc: 0.6875\n",
            "Iteration: 1120: Loss: 0.49306079745292664, Acc: 0.8125\n",
            "Iteration: 1140: Loss: 0.47598785161972046, Acc: 0.8125\n",
            "Iteration: 1160: Loss: 0.525635838508606, Acc: 0.75\n",
            "Iteration: 1180: Loss: 0.7022157907485962, Acc: 0.875\n",
            "Iteration: 1200: Loss: 0.940971314907074, Acc: 0.625\n",
            "Iteration: 1220: Loss: 0.7018245458602905, Acc: 0.6875\n",
            "Iteration: 1240: Loss: 0.8542772531509399, Acc: 0.5625\n",
            "Iteration: 1260: Loss: 0.3036324977874756, Acc: 0.875\n",
            "Iteration: 1280: Loss: 0.584162175655365, Acc: 0.6875\n",
            "Iteration: 1300: Loss: 0.5646447539329529, Acc: 0.8125\n",
            "Iteration: 1320: Loss: 0.43186065554618835, Acc: 0.8125\n",
            "Iteration: 1340: Loss: 0.5626659393310547, Acc: 0.625\n",
            "Iteration: 1360: Loss: 0.6806464791297913, Acc: 0.6875\n",
            "Epoch 1 Avg Loss - 0.6262427242981631\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁████████████████████</td></tr><tr><td>iteration</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇█</td></tr><tr><td>train/acc</td><td>▃▂▅▄▁▃▅▅▁▃▃▂▆▅▅▅▃▅▅▆▅▂▆▅▅▅▇▇▅▆▇▇▇█▇▅▅▇▇▇</td></tr><tr><td>train/loss</td><td>▆▇▆▄▅▅▅▆▇▄▄▄▅▅▃▃▄▃█▄▄▄▄▃▃▂▅▁▂▄▃▃▃▂▂▂▂▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>iteration</td><td>1363</td></tr><tr><td>train/acc</td><td>0.66667</td></tr><tr><td>train/loss</td><td>0.66633</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">eager-elevator-7</strong> at: <a href='https://wandb.ai/saahith/dear-watson/runs/ceqkkjm6' target=\"_blank\">https://wandb.ai/saahith/dear-watson/runs/ceqkkjm6</a><br> View project at: <a href='https://wandb.ai/saahith/dear-watson' target=\"_blank\">https://wandb.ai/saahith/dear-watson</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251107_062512-ceqkkjm6/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "all_preds = []\n",
        "all_ids = []\n",
        "\n",
        "cls_model.eval()\n",
        "\n",
        "for batch in test_loader:\n",
        "\n",
        "  with torch.no_grad():\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_masks\"].to(device)\n",
        "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "\n",
        "    inputs = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    ids = batch[\"ids\"]\n",
        "\n",
        "    logits, _ = cls_model(inputs)\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    preds = preds.tolist()\n",
        "\n",
        "    all_preds += preds\n",
        "    all_ids += ids"
      ],
      "metadata": {
        "id": "ZyUJULShnVDe"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the collected IDs and predictions\n",
        "submission_df = pd.DataFrame({\n",
        "    \"id\": all_ids,\n",
        "    \"prediction\": all_preds\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file, index=False is required by Kaggle\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Submission file created successfully!\")\n",
        "print(submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOBV30Y_5TZd",
        "outputId": "f0de82e3-b72b-46aa-ab52-9b58cb0477d5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file created successfully!\n",
            "           id  prediction\n",
            "0  c6d58c3f69           2\n",
            "1  cefcc82292           1\n",
            "2  e98005252c           0\n",
            "3  58518c10ba           1\n",
            "4  c32b0d16df           2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader = DataLoader(val_ds, batch_size=16, collate_fn=my_collate_fn)"
      ],
      "metadata": {
        "id": "uByw5zkE_cT_"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inference\n",
        "all_preds = []\n",
        "all_ids = []\n",
        "\n",
        "cls_model.eval()\n",
        "total_num_samples = 0\n",
        "total_correct = 0\n",
        "\n",
        "for batch in val_loader:\n",
        "\n",
        "  with torch.no_grad():\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_masks\"].to(device)\n",
        "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "    labels = batch[\"labels\"].to(device)\n",
        "\n",
        "    inputs = {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"token_type_ids\": token_type_ids\n",
        "    }\n",
        "\n",
        "    logits, _ = cls_model(inputs)\n",
        "\n",
        "    _, preds = torch.max(logits, dim=1)\n",
        "    num_correct = torch.sum(preds == labels)\n",
        "\n",
        "    total_correct += num_correct.item()\n",
        "    total_num_samples += len(preds)\n",
        "\n",
        "\n",
        "validation_accuracy = total_correct / total_num_samples\n",
        "print(f\"validation acc: {validation_accuracy}: {total_correct}/{total_num_samples}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Q_QtCy6A5n",
        "outputId": "4e187145-91f3-4331-a1b8-f4792c891e85"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation acc: 0.6674917491749175: 809/1212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z-g4I1oUBZzd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}